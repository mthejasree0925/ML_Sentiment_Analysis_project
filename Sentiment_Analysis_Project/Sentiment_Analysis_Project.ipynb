{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e1bcc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\life\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing all the neccessary libraries\n",
    "%matplotlib inline\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer, CountVectorizer\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_score, recall_score, f1_score\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "#from gensim.models import Word2Vec, KeyedVectors\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn import datasets, neighbors\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "from matplotlib.colors import ListedColormap\n",
    "#import scikitplot.metrics as sciplot\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math\n",
    "import nltk\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecd20e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### The immediate code block below does the following things :\n",
    "\n",
    "1. Load the Amazon dataset.\n",
    "2. Classify the reviews initially based on their score rating and give them a 'Positve' or a 'Negative' tag.\n",
    "3. Remove duplicate/redundant datas.\n",
    "4. Get an idea of how much percentage data were actually duplicates.\n",
    "5. Plot a histogram which will display the distribution of the number of positive and negative reviews after de-duplication.\n",
    "\n",
    "###### NOTE : If we dont' clean the data and feed them to an ML system, it basically means we are throwing in a lot of garbage data to the ML system. If we give it garbage, it will give us garbage back. So it's utmost important to clean the data before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd74c010",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data=pd.read_csv(\"Reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97dc8359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8706399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568454, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4489a9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = filtered_data.sample(frac=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3544a0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22738, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b61d9bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118958</th>\n",
       "      <td>118959</td>\n",
       "      <td>B000G1CG50</td>\n",
       "      <td>A10VDLEO35I25F</td>\n",
       "      <td>ferrethouse \"ferrethouse\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1296345600</td>\n",
       "      <td>Treats even my cats want!</td>\n",
       "      <td>My dogs love these treats &amp; my cats will follo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386642</th>\n",
       "      <td>386643</td>\n",
       "      <td>B007SI3WAM</td>\n",
       "      <td>A5L3L318Q55FI</td>\n",
       "      <td>Alfie's Pal \"Bichon Mom\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1307404800</td>\n",
       "      <td>Surprisingly Good Tea from Amazon</td>\n",
       "      <td>I was hesitant about ordering this the first t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91496</th>\n",
       "      <td>91497</td>\n",
       "      <td>B000EF3E2W</td>\n",
       "      <td>A2HQ88XFHZM9OV</td>\n",
       "      <td>LibertyBelle</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1235865600</td>\n",
       "      <td>Great Buy!</td>\n",
       "      <td>We have eaten this product for years and years...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85113</th>\n",
       "      <td>85114</td>\n",
       "      <td>B0055ZU898</td>\n",
       "      <td>A3MJ1A3RN6DMAE</td>\n",
       "      <td>Michael J. Markowitz \"consumer\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1345161600</td>\n",
       "      <td>very good coffee</td>\n",
       "      <td>If you're hooked on illy, as my wife and I are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143586</th>\n",
       "      <td>143587</td>\n",
       "      <td>B0007A0AQM</td>\n",
       "      <td>A332ZFX8S3A155</td>\n",
       "      <td>vinb \"vin b\"</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1276300800</td>\n",
       "      <td>Great training treats!</td>\n",
       "      <td>My dog loves these!  I've only tried the salmo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId                      ProfileName  \\\n",
       "118958  118959  B000G1CG50  A10VDLEO35I25F        ferrethouse \"ferrethouse\"   \n",
       "386642  386643  B007SI3WAM   A5L3L318Q55FI         Alfie's Pal \"Bichon Mom\"   \n",
       "91496    91497  B000EF3E2W  A2HQ88XFHZM9OV                     LibertyBelle   \n",
       "85113    85114  B0055ZU898  A3MJ1A3RN6DMAE  Michael J. Markowitz \"consumer\"   \n",
       "143586  143587  B0007A0AQM  A332ZFX8S3A155                     vinb \"vin b\"   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "118958                     0                       0      5  1296345600   \n",
       "386642                     0                       0      4  1307404800   \n",
       "91496                      5                       5      5  1235865600   \n",
       "85113                      0                       0      5  1345161600   \n",
       "143586                     5                       7      5  1276300800   \n",
       "\n",
       "                                  Summary  \\\n",
       "118958          Treats even my cats want!   \n",
       "386642  Surprisingly Good Tea from Amazon   \n",
       "91496                          Great Buy!   \n",
       "85113                    very good coffee   \n",
       "143586             Great training treats!   \n",
       "\n",
       "                                                     Text  \n",
       "118958  My dogs love these treats & my cats will follo...  \n",
       "386642  I was hesitant about ordering this the first t...  \n",
       "91496   We have eaten this product for years and years...  \n",
       "85113   If you're hooked on illy, as my wife and I are...  \n",
       "143586  My dog loves these!  I've only tried the salmo...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a485ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Give reviews with Score > 3 a 'Positive' tag, and reviews with a score < 3 a 'Negative' tag.\n",
    "filtered_data['SentimentPolarity'] = filtered_data['Score'].apply(lambda x : 'Positive' if x > 3 else 'Negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65539827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>SentimentPolarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118958</th>\n",
       "      <td>118959</td>\n",
       "      <td>B000G1CG50</td>\n",
       "      <td>A10VDLEO35I25F</td>\n",
       "      <td>ferrethouse \"ferrethouse\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1296345600</td>\n",
       "      <td>Treats even my cats want!</td>\n",
       "      <td>My dogs love these treats &amp; my cats will follo...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386642</th>\n",
       "      <td>386643</td>\n",
       "      <td>B007SI3WAM</td>\n",
       "      <td>A5L3L318Q55FI</td>\n",
       "      <td>Alfie's Pal \"Bichon Mom\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1307404800</td>\n",
       "      <td>Surprisingly Good Tea from Amazon</td>\n",
       "      <td>I was hesitant about ordering this the first t...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId                ProfileName  \\\n",
       "118958  118959  B000G1CG50  A10VDLEO35I25F  ferrethouse \"ferrethouse\"   \n",
       "386642  386643  B007SI3WAM   A5L3L318Q55FI   Alfie's Pal \"Bichon Mom\"   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "118958                     0                       0      5  1296345600   \n",
       "386642                     0                       0      4  1307404800   \n",
       "\n",
       "                                  Summary  \\\n",
       "118958          Treats even my cats want!   \n",
       "386642  Surprisingly Good Tea from Amazon   \n",
       "\n",
       "                                                     Text SentimentPolarity  \n",
       "118958  My dogs love these treats & my cats will follo...          Positive  \n",
       "386642  I was hesitant about ordering this the first t...          Positive  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b429cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentPolarity\n",
       "Positive    17759\n",
       "Negative     4979\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data['SentimentPolarity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cab4ec95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#score greater than 3 as postive  and equal to 3 as neutral and less than 3 as negative\n",
    "#filtered_data['SentimentPolarity'] = filtered_data['Score'].apply(lambda x : 'Positive' if x > 3 else (if x < 3 else 'Neutral'))\n",
    "#score greater than 3 as postive  and equal to 3 as neutral and less than 3 as negative and give more priority to negative words\n",
    "#filtered_data['SentimentPolarity'] = filtered_data['Score'].apply(lambda x : 'Positive' if x > 3 else ('Negative' if x < 3 else 'Neutral'))\n",
    "filtered_data['Class_Labels'] = filtered_data['SentimentPolarity'].apply(lambda x : 1 if x == 'Positive' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec32c2b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>SentimentPolarity</th>\n",
       "      <th>Class_Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118958</th>\n",
       "      <td>118959</td>\n",
       "      <td>B000G1CG50</td>\n",
       "      <td>A10VDLEO35I25F</td>\n",
       "      <td>ferrethouse \"ferrethouse\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1296345600</td>\n",
       "      <td>Treats even my cats want!</td>\n",
       "      <td>My dogs love these treats &amp; my cats will follo...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386642</th>\n",
       "      <td>386643</td>\n",
       "      <td>B007SI3WAM</td>\n",
       "      <td>A5L3L318Q55FI</td>\n",
       "      <td>Alfie's Pal \"Bichon Mom\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1307404800</td>\n",
       "      <td>Surprisingly Good Tea from Amazon</td>\n",
       "      <td>I was hesitant about ordering this the first t...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId                ProfileName  \\\n",
       "118958  118959  B000G1CG50  A10VDLEO35I25F  ferrethouse \"ferrethouse\"   \n",
       "386642  386643  B007SI3WAM   A5L3L318Q55FI   Alfie's Pal \"Bichon Mom\"   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "118958                     0                       0      5  1296345600   \n",
       "386642                     0                       0      4  1307404800   \n",
       "\n",
       "                                  Summary  \\\n",
       "118958          Treats even my cats want!   \n",
       "386642  Surprisingly Good Tea from Amazon   \n",
       "\n",
       "                                                     Text SentimentPolarity  \\\n",
       "118958  My dogs love these treats & my cats will follo...          Positive   \n",
       "386642  I was hesitant about ordering this the first t...          Positive   \n",
       "\n",
       "        Class_Labels  \n",
       "118958             1  \n",
       "386642             1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7953582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22738, 12)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "985dc257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of positive and negative reviews before the removal of duplicate data.\n",
      "SentimentPolarity\n",
      "Positive    17759\n",
      "Negative     4979\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of positive and negative reviews before the removal of duplicate data.\")\n",
    "print(filtered_data[\"SentimentPolarity\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20503cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing duplicate entries based on past knowledge.\n",
    "filtered_duplicates=filtered_data.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"}, keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8e39f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of positive and negative reviews after the removal of duplicate data.\n",
      "SentimentPolarity\n",
      "Positive    17099\n",
      "Negative     4793\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of positive and negative reviews after the removal of duplicate data.\")\n",
    "print(filtered_data[\"SentimentPolarity\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e35d11e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the entries where HelpfulnessNumerator > HelpfulnessDenominator.\n",
    "final_data=filtered_data[filtered_data.HelpfulnessNumerator <= filtered_data.HelpfulnessDenominator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0692003f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentPolarity\n",
       "Positive    17099\n",
       "Negative     4793\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data[\"SentimentPolarity\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877c5fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### In this code block :\n",
    "\n",
    "1. I am creating a copy of the final_data dataset called 'sampled_dataset' by dropping the unwanted columns that we don't need for this problem.\n",
    "2. Sorting the data according to time, such that the oldest reviews are displayed at the top and the latest reviews are displayed at the bottom.\n",
    "3. Displaying information about the number of postive and negative reviews in the sampled dataset, using a Histogram."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bb7d93",
   "metadata": {},
   "source": [
    "#Dropping unwanted columns for now.\n",
    "sampled_dataset=final_data.drop(labels=['Id','ProductId', 'UserId', 'Score', 'ProfileName','HelpfulnessNumerator', 'HelpfulnessDenominator','Summary'], axis=1)\n",
    "print(\"The shape of the sampled dataset after dropping unwanted columns : \", sampled_dataset.shape)\n",
    "sampled_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2abf108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the sampled dataset after dropping unwanted columns :  (21892, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Text</th>\n",
       "      <th>SentimentPolarity</th>\n",
       "      <th>Class_Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118958</th>\n",
       "      <td>1296345600</td>\n",
       "      <td>My dogs love these treats &amp; my cats will follo...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386642</th>\n",
       "      <td>1307404800</td>\n",
       "      <td>I was hesitant about ordering this the first t...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91496</th>\n",
       "      <td>1235865600</td>\n",
       "      <td>We have eaten this product for years and years...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85113</th>\n",
       "      <td>1345161600</td>\n",
       "      <td>If you're hooked on illy, as my wife and I are...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143586</th>\n",
       "      <td>1276300800</td>\n",
       "      <td>My dog loves these!  I've only tried the salmo...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Time                                               Text  \\\n",
       "118958  1296345600  My dogs love these treats & my cats will follo...   \n",
       "386642  1307404800  I was hesitant about ordering this the first t...   \n",
       "91496   1235865600  We have eaten this product for years and years...   \n",
       "85113   1345161600  If you're hooked on illy, as my wife and I are...   \n",
       "143586  1276300800  My dog loves these!  I've only tried the salmo...   \n",
       "\n",
       "       SentimentPolarity  Class_Labels  \n",
       "118958          Positive             1  \n",
       "386642          Positive             1  \n",
       "91496           Positive             1  \n",
       "85113           Positive             1  \n",
       "143586          Positive             1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dropping unwanted columns for now.\n",
    "sampled_dataset=final_data.drop(labels=['Id','ProductId', 'UserId', 'Score', 'ProfileName','HelpfulnessNumerator', 'HelpfulnessDenominator','Summary'], axis=1)\n",
    "print(\"The shape of the sampled dataset after dropping unwanted columns : \", sampled_dataset.shape)\n",
    "sampled_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "548735db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting data according to Time in ascending order => Time Based Splitting Step 1.\n",
    "sampled_dataset=sampled_dataset.sort_values('Time', axis=0, ascending=False, inplace=False, kind='quicksort', na_position='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e90a02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting data according to Time in ascending order => Time Based Splitting Step 1.\n",
    "sampled_dataset=sampled_dataset.sort_values('Time', axis=0, ascending=False, inplace=False, kind='quicksort', na_position='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b495397",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_dataset = sampled_dataset.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ece82290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Time</th>\n",
       "      <th>Text</th>\n",
       "      <th>SentimentPolarity</th>\n",
       "      <th>Class_Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>193974</td>\n",
       "      <td>1351209600</td>\n",
       "      <td>This stuff is great for my non-black tea drink...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>467555</td>\n",
       "      <td>1351209600</td>\n",
       "      <td>I have used Alessi Decaffenated Caffe'Expresso...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index        Time                                               Text  \\\n",
       "0  193974  1351209600  This stuff is great for my non-black tea drink...   \n",
       "1  467555  1351209600  I have used Alessi Decaffenated Caffe'Expresso...   \n",
       "\n",
       "  SentimentPolarity  Class_Labels  \n",
       "0          Positive             1  \n",
       "1          Positive             1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sampled_dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09fd06d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_dataset=sampled_dataset.drop(labels=['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d4ea4f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Distribution Of Positive and Negative reviews after De-Duplication.'}, xlabel='SentimentPolarity'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkEAAAIFCAYAAADVzSnXAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAX2FJREFUeJzt3XlYVOX/PvB72BdhZB+nQNQURXAJE8FKTQVLJEtzwXBHzdRQcatMbYFccqVFrcQd+6SYC5FoSpG4YWiaZhYJBogLDuLC+vz+8Mf5OgwgKDDBuV/XNdflPOc95zxnZs6cm+csKoQQAkREREQyY6DvDhARERHpA0MQERERyRJDEBEREckSQxARERHJEkMQERERyRJDEBEREckSQxARERHJEkMQERERyRJDEBEREclStUJQVFQUFAqF9DAzM4NKpUKPHj0QERGB7OxsndfMnz8fCoWiWp26c+cO5s+fj0OHDlXrdeUty9XVFQEBAdWaz8Ns2bIFy5cvL3eaQqHA/Pnza3R51XHkyBG89tpraNKkCUxMTKBSqTBw4EAkJSWVW79t2za0bdsW5ubmUCgUSElJKbfu0KFDWp+9oaEhnJyc8Nprr+HcuXO1si6urq4YOXKk9DwjIwPz588vt4+P8j2rb7p3747u3bs/tM7V1RUKhQITJkzQmVb6OX777be10MPqO3z4MObPn4+bN2/qTKvq+tZn+v69qA2//vorunXrBqVSCYVCgeXLlyM2NrbO17P0N6H0YWFhgSeffBL+/v5YtWoVbt26VePLLPs7aWJiAgcHB3Tt2hXvvPMOLl26VOPLrKwfD+5Da/s3st5uy6Ia1q1bJwCIdevWiaSkJPHTTz+Jb7/9VoSGhgqlUilsbW1FfHy81mvS09NFUlJSdRYjrl69KgCIefPmVet15S2radOmom/fvtWaz8P07dtXNG3atNxpSUlJIj09vUaXV1UrV64UBgYGokuXLmLDhg0iISFBbNy4UXTp0kUYGBiIVatWadVnZ2cLY2Nj0a9fP3Ho0CGRlJQkbt++Xe68Dx48KACI8PBwkZSUJBISEsQnn3wilEqlsLGxEZcvX67x9Tl58qS4ePGi9Pz48ePS96+sR/me1TfdunUT3bp1e2hd06ZNBQBhZGQkzp8/rzWt9HP83//+V0u9rJ7FixcLACI1NVVn2tmzZ8XZs2frvlN1SJ+/F7WlQ4cOomXLliI2NlYkJSWJzMxM8eabb4pq7m4e27x58wQAERcXJ/1mbd26VYwdO1aYmZkJZ2dnkZKSUqPLLPs7mZiYKL777jvx9ttvC5VKJczNzcWmTZtqdJmV9ePgwYNSW23/RtbXbfmRQtDx48d1pl26dEk4OzsLKysrkZWV9Vidqm4IqmjHLUTdhyB9SUxMFAYGBiIgIEAUFhZqTSssLBQBAQHCwMBAJCYmar0GgNi2bdtD51/RzvOrr74SAMSHH35YMytSicpCkBxUJwT5+PgIpVIpXn31Va1p9SkE/ZdU9htD2oyMjMQbb7yh1VZbIaiyz6U0BF29elVnWkpKilAqlcLFxUXcu3evxvpT2fZ1/fp10bFjR2FkZCROnz5dY8usrB8PhqDaVl+25bJqLAQJIcQ333wjAIgFCxZIbaVfxAcdOHBAdOvWTdja2kqJ/NVXXxW3b98WqampAoDOY8SIEVrzS05OFgMGDBCNGzcWKpWqwmWVhqAdO3YIT09PYWpqKpo1ayZWrFhR7rqV/QDLfpm6detWbv9KlRfefvvtNxEYGCgaN24sTE1NRfv27UVUVFS5y9myZYt4++23RZMmTYSVlZXo2bOnzl/z5enbt68wNDSs8K/KtLQ0YWhoKAICAoQQQowYMUJnHSrbwVa0cZ89e1YAECEhIUIIIYqLi8XChQuFm5ubMDExEQ4ODiI4OFinXydPnhR9+/YVDg4OwsTERDRp0kS89NJLWnVNmzaVPvfS5Zd9lL7XZT/7l19+Wbi4uIji4mKddencubPo2LGj9LykpER8+umnon379sLMzEw0btxYDBgwQPz1118Vvh+l/vzzTzFy5Ejx1FNPCXNzc6FWq0VAQIDOj1x1Pt+SkhKxcOFC4eLiIkxNTUXHjh1FbGxstUJQ3759RUREhACg9ddfRZ/jhQsXxNChQ6XPo3Xr1iIyMlJn3mfOnBG9e/cW5ubmwt7eXkycOFHs2bNH5wd33759IjAwUDzxxBPC1NRUtGjRQowbN05rh1T6mZV9PLitla5vQUGBcHBwEK+//rpOn3JycoSZmZmYOnWq1KbRaMT06dOFq6urMDY2Fmq1Wrz11lsiLy/voe9ft27dRNu2bUVCQoLw8fER5ubmYvDgwVWeb4cOHcSzzz6rM9+ioiKhVqvFK6+8IrWV93uRmZkpxo0bJ5544glhbGwsXF1dxfz587X+uOnUqZN46aWXtF7n4eEhAIhjx45Jbdu3bxcApO9jdna2CAkJEU8++aQwMTER9vb2wtfXV2cEv6yqfM9Lf0PL++0ur730t7aq219ln0t5KgtBQgixaNEiAUCsX79eqz0+Pl688MILwsrKSpibmwtfX1+xf//+St+fUg/7I+PYsWMCgBg1apTUNmLEiHL/qC5vfwZAvPnmm+KLL74QLVu2FCYmJqJNmzZi69at5fbjwW2yvPkJIcTmzZtFly5dhKWlpbC0tBTt27cXX375pTS9prflUtevXxdvvPGGUKvVwtjYWDRr1ky8/fbbOqG0dJ03bNggWrduLczNzUW7du3E7t27y32Pq6tGQ1BeXp4wNDQUPXv2lNrKvvGpqanCzMxM9O7dW+zcuVMcOnRIbN68WQQHB4ucnBxx7949ERcXJwCIMWPGiKSkJJGUlCQdFimdX9OmTcWsWbNEfHy82LlzZ7nLEuL+DuGJJ54QLi4u4uuvvxaxsbFi2LBhAoBYvHixzro9LASdPXtWdO3aVahUKqlvD+5kyv6onT9/XlhZWYkWLVqIDRs2iL1794qhQ4cKAGLhwoU6y3F1dRXDhg0Te/fuFVu3bhUuLi6iZcuWoqioqMLPpaioSFhYWAhvb+8Ka4S4v/O3sLAQRUVF4uLFi+LTTz/VGrqtbLiyoo37u+++EwDE22+/LYQQYty4cQKAmDRpkoiLixNffPGFcHBwEM7OztJGk5eXJ+zs7ESnTp3EN998IxISEsS2bdvEhAkTxO+//y7N+8EQpNFopM/o3Xffld730tBU9rMv7VfZH/dz584JAGLlypVSW0hIiDA2NhbTp08XcXFxYsuWLaJ169bCycnpoaOaCQkJYvr06eLbb78VCQkJIiYmRvTv31+Ym5trhZvqfL6l6zJmzBjx/fffizVr1ognnnhCqFSqaoWgO3fuiCeeeEI899xzOv148HM8e/asUCqVwtPTU2zYsEHs27dPTJ8+XRgYGIj58+dLdRkZGcLOzk64uLiIqKgoERsbK4KDg4Wrq6vOD+7nn38uIiIixK5du0RCQoJYv369aN++vXBzcxMFBQVCiPvD85MnTxYAxI4dO6TPVKPRCCF0fzinTp0qzM3NpemlPvvsM60d/e3bt0WHDh2Evb29WLp0qdi/f79YsWKFUCqV4oUXXhAlJSWVvn+lf6A5OzuLVatWiYMHD4qEhIQqz3fFihUCgLhw4YLWfGNjYwUAsWvXLqmt7O9FZmamcHZ2Fk2bNhWrV68W+/fvFx988IEwNTUVI0eOlOpmz54tGjVqJL2XWVlZAoAwNzcXH330kVT3xhtvCCcnJ+m5v7+/cHBwEGvWrBGHDh0SO3fuFO+9956Ijo6u9D2pyvc8OztbJCUlCQBi4MCBWr/dAwcOlAJ56aN0Z1fV7a+iz6UiDwtB58+fl7azUhs3bhQKhUL0799f7NixQ+zevVsEBAQIQ0PDKgWhqoy0NmnSRLRo0UJ6Xt0Q5OzsLNzd3cXWrVvFrl27RJ8+fXSWWdUQNHfuXAFAvPrqq+J///uf2Ldvn1i6dKmYO3euVFMb2/Ldu3dFu3bthKWlpViyZInYt2+fmDt3rjAyMtIJ96W/m507dxbffPONiI2NFd27dxdGRkZV+kP1YWo0BAkhhJOTk2jTpo30vOwb/+233woAlR6LrexwWOn83nvvvQqnPahp06ZCoVDoLK93797C2tpaGk6taggSovLDYWX7PWTIEGFqairS0tK06l588UVhYWEhbt68qbWcsl+A0tG1yo7llv4ADhkypMIaIYQYPHiwACCuXLmitcyqHBoprd22bZsoLCwUd+7cET/99JN46qmnhKGhoTh16pQUMCZOnKj12qNHj2oFpRMnTggAUnityIMhSIjKD4eV/ewLCwuFk5OTCAoK0qqbOXOmMDExEdeuXRNCCOlH+5NPPtGqS09PF+bm5mLmzJkPfW8eVFRUJAoKCkTLli21Riaq+vmWjmo8OFoghBC//PLLQ0frSj14CHjt2rUCgPRXU3mfub+/v3jyySd1wsWkSZOEmZmZuHHjhhBCiBkzZgiFQqETlv39/XW2kQeVlJSIwsJCcenSJQFAfPfdd9K0yobQy/5wnj59WgAQa9as0arr3Lmz8PLykp5HREQIAwMDnd+p0t+e2NjYcvv54HIBiAMHDmi1V3W+165dEyYmJtL3vdSgQYOEk5OT1ohO2d+L8ePHi0aNGolLly5pvXbJkiUCgPTe79+/XwAQP/30kxBCiE2bNgkrKysxceJE0aNHD+l1LVu21NoGGjVqJEJDQytd/6qo6Hteuk5vvvmmVltFh8Oqs/1V9LlU5GEh6O7duwKAePHFF4UQ98Ozra2t6Nevn1ZdcXGxaN++vejcufNDl1mV31Rvb29hbm4uPa9uCDI3N9cKh0VFRaJ169biqaee0ulHZSHo77//FoaGhmLYsGEPXa9SNbUtf/HFFwKA+Oabb7TqFi5cKACIffv2aa2zk5OTyM3NldqysrKEgYGBiIiIqHLfK1Ljl8jf73PFOnToABMTE4wbNw7r16/H33///UjLGTBgQJVr27Zti/bt22u1BQUFITc3FydPnnyk5VfVjz/+iJ49e8LZ2VmrfeTIkbhz547OVVuBgYFaz9u1awcANXJVQeln8zhXCAwePBjGxsawsLDA888/j+LiYnz77bdo164dDh48CABaV3QBQOfOndGmTRscOHAAAPDUU0/BxsYGs2bNwhdffIHff//9kftTESMjI7z++uvYsWMHNBoNAKC4uBgbN27Eyy+/DDs7OwDAnj17oFAo8Prrr6OoqEh6qFQqtG/f/qFXKBYVFSE8PBzu7u4wMTGBkZERTExM8Oeff5Z71dzDPt+kpCTcu3cPw4YN06rz9fVF06ZNq/0+jBo1Cu7u7pg9ezZKSkp0pt+7dw8HDhzAK6+8AgsLC6334KWXXsK9e/dw5MgRAEBCQgI8PDzg7u6uNY+hQ4fqzDc7OxsTJkyAs7MzjIyMYGxsLPX/Ua8m9PT0hJeXF9atWye1nTt3DseOHcPo0aOltj179sDDwwMdOnTQWh9/f3+dK2YqYmNjgxdeeEGrrarztbOzQ79+/bB+/XrpPc/JycF3332H4cOHw8jIqMLl7tmzBz169IBardZaxosvvgjg/mcAAF27doWZmRn2798PAIiPj0f37t3Rp08fHD58GHfu3EF6ejr+/PNP9OrVS5p/586dERUVhQ8//BBHjhxBYWHhQ98LoPrf86qq7vZX3ufyqMruqw4fPowbN25gxIgRWn0pKSlBnz59cPz4cdy+fRsAtKYXFRU9dL9X2XKrq2fPnnBycpKeGxoaYvDgwbh48SIuX75c5fnEx8ejuLgYb775ZqV1tbEt//jjj7C0tMTAgQO12kv3HaX7ilI9evSAlZWV9NzJyQmOjo41sl+s0RB0+/ZtXL9+HWq1usKaFi1aYP/+/XB0dMSbb76JFi1aoEWLFlixYkW1ltWkSZMq16pUqgrbrl+/Xq3lVtf169fL7Wvpe1R2+aU751KmpqYAgLt371a4DHt7e1hYWCA1NbXSvvzzzz+wsLCAra1tlfpenoULF+L48eM4efIk0tLS8Pfff6N///4A/m9dKlrf0ulKpRIJCQno0KED3n77bbRt2xZqtRrz5s2r8o9yVYwePRr37t1DdHQ0AOCHH35AZmYmRo0aJdVcuXIFQgg4OTnB2NhY63HkyBFcu3at0mVMmzYNc+fORf/+/bF7924cPXoUx48fR/v27cv9zB72+Za+R5V9Z6vD0NAQ4eHhOHv2LNavX68z/fr16ygqKsKqVat01v+ll14CAOk9uH79utaPb6mybSUlJfDz88OOHTswc+ZMHDhwAMeOHZPCVGXf5YcZPXo0kpKScP78eQDAunXrYGpqqhXErly5gtOnT+usj5WVFYQQD/1MgfK/w9WZ7+jRo/Hvv/8iPj4eALB161bk5+fr/IFQ3jJ2796ts4y2bdsC+L/PwszMDF27dpVC0IEDB9C7d290794dxcXF+Pnnn6VlPxiCtm3bhhEjRuDLL7+Ej48PbG1tMXz4cGRlZVXar+p+z6uquttfdX73H6Z0B1r6W3zlyhUAwMCBA3X6snDhQgghcOPGDfzzzz8600vDaVWkpaVVuo98mJran129ehUA8OSTT1ZYU1vb8vXr16FSqXT+IHd0dISRkdFD94vA/d/Ox/nular4T5JHsHfvXhQXFz/0fgDPPfccnnvuORQXF+PEiRNYtWoVQkND4eTkhCFDhlRpWdUZzShvAy9tK31zzczMAAD5+fladVX5wayMnZ0dMjMzddozMjIA3A8wj8vQ0BA9evRAXFwcLl++XO6X+vLly0hOTsaLL74IQ0PDR15W8+bN0alTp3Knlb6XmZmZOn3IyMjQWldPT09ER0dDCIHTp08jKioK77//PszNzTF79uxH7t+D3N3d0blzZ6xbtw7jx4/HunXroFar4efnJ9XY29tDoVDg559/lgLJg8pre9CmTZswfPhwhIeHa7Vfu3YNjRs3rnafS9/Dir6zrq6u1Z7nyy+/jK5du2LevHlYs2aN1jQbGxsYGhoiODi4wr8ImzVrJvWtdEdRtl8POnPmDE6dOoWoqCiMGDFCar948WK1+17W0KFDMW3aNERFReGjjz7Cxo0b0b9/f9jY2Eg19vb2MDc3x9dff13uPKqyzZX3+1Kd+fr7+0OtVmPdunXw9/fHunXr4O3trTOKVt482rVrh48++qjc6Q/uPHv27In33nsPx44dw+XLl9G7d29YWVnhmWeeQXx8PDIyMtCqVSutUWh7e3ssX74cy5cvR1paGnbt2oXZs2cjOzsbcXFxFfarpr/nD/anOttfTd7nZteuXQAg7a9KP79Vq1ahS5cu5b6mNPAfP35cq93Nza1Kyzx27BiysrIwZswYqc3MzExnvwNUvO+pyv6sKhwcHADc3zeUPVJRqra2ZTs7Oxw9ehRCCK3PNDs7G0VFRTWyX6yqGgtBaWlpCAsLg1KpxPjx46v0GkNDQ3h7e6N169bYvHkzTp48iSFDhlRp9KM6zp49i1OnTmkdEtuyZQusrKzw9NNPA4C0czl9+rTWF7p0Q3lQdRJoz549ERMTg4yMDK0fsA0bNsDCwqLCja265syZg++//x4TJ05ETEyMVtApLi7GG2+8ASEE5syZUyPLK0/pMPWmTZvwzDPPSO3Hjx/HuXPn8M477+i8RqFQoH379li2bBmioqIqPTz5KN+LUaNG4Y033kBiYiJ2796NadOmab03AQEB+Pjjj/Hvv/9i0KBBVZ7vg/0v+0O9d+9e/Pvvv3jqqaeqPb8uXbrAzMwMmzdv1jrke/jwYVy6dOmRQhBwfwTv2WefxcqVK7XaLSws0KNHD/z6669o164dTExMKpxHt27dsGTJEvz+++9aO/PSkbZSpT9qZd+X1atX68yzup+pjY0N+vfvjw0bNsDHxwdZWVlah8KA+59peHg47OzspABXE6oz39JguXz5cvz88884ceJEuetf3jJiY2PRokULrWBXnl69euHtt9/G3Llz8eSTT6J169ZS+65du5CVlVXpaQMuLi6YNGkSDhw4gF9++aXSZT3u9/zBz9nc3Fxqf9zt71GdOnUK4eHhcHV1lZbbtWtXNG7cGL///jsmTZpU6esr+kOwMjdu3MCECRNgbGyMqVOnSu2urq7Izs7GlStXpJBVUFCAH374odz5HDhwQKu2uLgY27ZtQ4sWLSod1SnLz88PhoaG+Pzzz+Hj41NuTW1tyz179sQ333yDnTt34pVXXpHaN2zYIE2vK48Ugs6cOSMdC83OzsbPP/+MdevWwdDQEDExMVLCLM8XX3yBH3/8EX379oWLiwvu3bsn/WVVOmxrZWWFpk2b4rvvvkPPnj1ha2sLe3v7R94BqNVqBAYGYv78+WjSpAk2bdqE+Ph4LFy4EBYWFgCAZ555Bm5ubggLC0NRURFsbGwQExODxMREnfl5enpix44d+Pzzz+Hl5QUDA4MKN4p58+ZJx/nfe+892NraYvPmzdi7dy8WLVoEpVL5SOtUVteuXbF8+XKEhobi2WefxaRJk+Di4oK0tDR8+umnOHr0KJYvXw5fX98aWV553NzcMG7cOKxatQoGBgZ48cUX8c8//2Du3LlwdnaWNvw9e/bgs88+Q//+/dG8eXMIIbBjxw7cvHkTvXv3rnD+LVq0gLm5OTZv3ow2bdqgUaNGUKvVlQ4tl44cDB06tNzDEV27dsW4ceMwatQonDhxAs8//zwsLS2RmZmJxMREeHp64o033qhw/gEBAYiKikLr1q3Rrl07JCcnY/HixdX6MXqQjY0NwsLC8OGHH2Ls2LF47bXXkJ6ejvnz5z/S4bBSXbt2xcsvv4zvvvtOZ9qKFSvw7LPP4rnnnsMbb7wBV1dX3Lp1CxcvXsTu3bvx448/AgBCQ0Px9ddf48UXX8T7778PJycnbNmyRTo0ZWBw/+h669at0aJFC8yePRtCCNja2mL37t3S4ZkHeXp6Sn0YMWIEjI2N4ebmpnX8v6zRo0dj27ZtmDRpEp588kmtwz2l/dy+fTuef/55TJ06Fe3atUNJSQnS0tKwb98+TJ8+Hd7e3tV+D6s739GjR2PhwoUICgqCubk5Bg8e/NBlvP/++4iPj4evry+mTJkCNzc33Lt3D//88w9iY2PxxRdfSN8tLy8v2NjYYN++fVqHeHv16oUPPvhA+ncpjUaDHj16ICgoCK1bt4aVlRWOHz+OuLg4vPrqq5X263G/56Wf88KFC6XR6Hbt2j329lcVycnJUCqVKCwsREZGBg4cOICNGzfC0dERu3fvloJ/o0aNsGrVKowYMQI3btzAwIED4ejoiKtXr+LUqVO4evUqPv/88yot888//8SRI0dQUlKC69ev4+jRo/jqq6+Qm5uLDRs2SIc3gfvnWb733nsYMmQIZsyYgXv37mHlypUoLi4ud9729vZ44YUXMHfuXFhaWuKzzz7D+fPndf4YeRhXV1e8/fbb+OCDD3D37l0MHToUSqUSv//+O65du4YFCxbU2rY8fPhwfPrppxgxYgT++ecfeHp6IjExEeHh4XjppZd0tumqSEhIkEZH33vvvaq/sDpnUZe9D4SJiYlwdHQU3bp1E+Hh4SI7O1vnNWXPSE9KShKvvPKKaNq0qTA1NRV2dnaiW7duWpeNCnH/6oeOHTsKU1NTAejeJ6i8M/4ru0/Qt99+K9q2bStMTEyEq6urWLp0qc7rL1y4IPz8/IS1tbVwcHAQkydPFnv37tU5y/7GjRti4MCBonHjxkKhUGgtE+Vc1fbbb7+Jfv36CaVSKUxMTET79u11rnCq6KqC0vsmVfUGgUlJSWLgwIHCyclJGBkZCUdHR/Hqq6+Kw4cP69Q+ytVhD6stvU9Qq1athLGxsbC3txevv/661v1/zp8/L4YOHSpatGghzM3NhVKpFJ07d9a5d1LZq8OEEGLr1q2idevWwtjYWOu9rugeGEIIERQUJACIrl27Vtjvr7/+Wnh7ewtLS0thbm4uWrRoIYYPHy5OnDhR6frm5OSIMWPGCEdHR2FhYSGeffZZ8fPPP+tcDVGdz7ekpEREREQIZ2dnYWJiIt0To7r3CSrr999/F4aGhhX2Y/To0dK9aRwcHISvr6/OTTDPnDkjevXqJczMzIStra0YM2aMWL9+vQAgTp06pbWs3r17CysrK2FjYyNee+01kZaWVu72MWfOHKFWq4WBgYHWtlbR+hYXFwtnZ2cBQLzzzjvlvgd5eXni3Xffle5XVXoLgKlTpz70tgel96Opifn6+voKABVegVPe+3H16lUxZcoU0axZM2FsbCxsbW2Fl5eXeOedd3Tuc/TKK68IAGLz5s1SW0FBgbC0tBQGBgYiJydHar93756YMGGCaNeunbC2thbm5ubCzc1NzJs376E3g6zq97x0ncpeHZafny/Gjh0rHBwcpN/MB68iqsr2V9nnUp6y964xNTUVTZo0EX5+fmLFihVaVxs9KCEhQfTt21fY2toKY2Nj8cQTT4i+fftW63ey9GFkZCTs7OyEj4+PePvtt8U///xT7utiY2NFhw4dhLm5uWjevLmIjIys9D5Bn332mWjRooUwNjYWrVu31vr8H+xHVe4TtGHDBvHMM88IMzMz0ahRI9GxY0et36Pa2pavX78uJkyYIJo0aSKMjIxE06ZNxZw5cyq8T1BZZfcPpetc3f9pQvH/F0JE9EjGjRuHrVu34vr165UeTiOix6NQKPDmm28iMjJS311pMGr0xGgiatjef/99qNVqNG/eHHl5edizZw++/PJLvPvuuwxARFTvMAQRUZUZGxtj8eLFuHz5MoqKitCyZUssXboUb731lr67RkRUbTwcRkRERLJU43eMJiIiIqoPGIKIiIhIlhiCiIiISJZ4YrSelJSUICMjA1ZWVjV6K3giIqo/hBC4desW1Gq1dMNRqjsMQXqSkZFR4f/XQkRE8pKenv7Id5qnR8cQpCeltxJPT0+HtbW1nntDRET6kJubC2dn50r/qxiqPQxBelJ6CMza2pohiIhI5nhahH7wACQRERHJEkMQERERyRJDEBEREckSQxARERHJEkMQERERyRJDEBEREckSQxARERHJEkMQERERyRJDEBEREckSQxARERHJEkMQERERyRJDEBEREckSQxARERHJEkMQERERyRJDEBEREckSQxARERHJkpG+O0D1l2KBQt9dkD0xT+i7C0RE9RZHgoiIiEiWGIKIiIhIlhiCiIiISJYYgoiIiEiWGIKIiIhIlhiCiIiISJYYgoiIiEiWGIKIiIhIlhiCiIiISJYYgoiIiEiWGIKIiIhIlhiCiIiISJYYgoiIiEiWGIKIiIhIlhiCiIiISJYYgoiIiEiWGIKIiIhIlhiCiIiISJbqTQj66aef0K9fP6jVaigUCuzcuVOn5ty5cwgMDIRSqYSVlRW6dOmCtLQ0aXp+fj4mT54Me3t7WFpaIjAwEJcvX9aaR05ODoKDg6FUKqFUKhEcHIybN29q1aSlpaFfv36wtLSEvb09pkyZgoKCgtpYbSIiIqol9SYE3b59G+3bt0dkZGS50//66y88++yzaN26NQ4dOoRTp05h7ty5MDMzk2pCQ0MRExOD6OhoJCYmIi8vDwEBASguLpZqgoKCkJKSgri4OMTFxSElJQXBwcHS9OLiYvTt2xe3b99GYmIioqOjsX37dkyfPr32Vp6IiIhqnEIIIfTdiepSKBSIiYlB//79pbYhQ4bA2NgYGzduLPc1Go0GDg4O2LhxIwYPHgwAyMjIgLOzM2JjY+Hv749z587B3d0dR44cgbe3NwDgyJEj8PHxwfnz5+Hm5obvv/8eAQEBSE9Ph1qtBgBER0dj5MiRyM7OhrW1dZXWITc3F0qlEhqNpsqv+a9RLFDouwuyJ+bVu82XiB7QEPYF9Vm9GQmqTElJCfbu3YtWrVrB398fjo6O8Pb21jpklpycjMLCQvj5+UltarUaHh4eOHz4MAAgKSkJSqVSCkAA0KVLFyiVSq0aDw8PKQABgL+/P/Lz85GcnFxhH/Pz85Gbm6v1ICIiIv1pECEoOzsbeXl5+Pjjj9GnTx/s27cPr7zyCl599VUkJCQAALKysmBiYgIbGxut1zo5OSErK0uqcXR01Jm/o6OjVo2Tk5PWdBsbG5iYmEg15YmIiJDOM1IqlXB2dn6sdSYiIqLH0yBCUElJCQDg5ZdfxtSpU9GhQwfMnj0bAQEB+OKLLyp9rRACCsX/HdZ58N+PU1PWnDlzoNFopEd6evpD14uIiIhqT4MIQfb29jAyMoK7u7tWe5s2baSrw1QqFQoKCpCTk6NVk52dLY3sqFQqXLlyRWf+V69e1aopO+KTk5ODwsJCnRGiB5mamsLa2lrrQURERPrTIEKQiYkJnnnmGfzxxx9a7RcuXEDTpk0BAF5eXjA2NkZ8fLw0PTMzE2fOnIGvry8AwMfHBxqNBseOHZNqjh49Co1Go1Vz5swZZGZmSjX79u2DqakpvLy8am0diYiIqGYZ6bsDVZWXl4eLFy9Kz1NTU5GSkgJbW1u4uLhgxowZGDx4MJ5//nn06NEDcXFx2L17Nw4dOgQAUCqVGDNmDKZPnw47OzvY2toiLCwMnp6e6NWrF4D7I0d9+vRBSEgIVq9eDQAYN24cAgIC4ObmBgDw8/ODu7s7goODsXjxYty4cQNhYWEICQnh6A4REVE9Um8ukT906BB69Oih0z5ixAhERUUBAL7++mtERETg8uXLcHNzw4IFC/Dyyy9Ltffu3cOMGTOwZcsW3L17Fz179sRnn32mdZLyjRs3MGXKFOzatQsAEBgYiMjISDRu3FiqSUtLw8SJE/Hjjz/C3NwcQUFBWLJkCUxNTau8Pg3hskheIq9/vESeqH5rCPuC+qzehKCGpiF88RmC9I8hiKh+awj7gvqsQZwTRERERFRdDEFEREQkSwxBREREJEsMQURERCRLDEFEREQkSwxBREREJEsMQURERCRLDEFEREQkSwxBREREJEsMQURERCRLDEFEREQkSwxBREREJEsMQURERCRLDEFEREQkSwxBREREJEsMQURERCRLDEFEREQkSwxBREREJEsMQURERCRLDEFEREQkSwxBREREJEsMQURERCRLDEFEREQkSwxBREREJEsMQURERCRLDEFEREQkSwxBREREJEsMQURERCRLDEFEREQkSwxBREREJEsMQURERCRLDEFEREQkS/UmBP3000/o168f1Go1FAoFdu7cWWHt+PHjoVAosHz5cq32/Px8TJ48Gfb29rC0tERgYCAuX76sVZOTk4Pg4GAolUoolUoEBwfj5s2bWjVpaWno168fLC0tYW9vjylTpqCgoKCG1pSIiIjqQr0JQbdv30b79u0RGRlZad3OnTtx9OhRqNVqnWmhoaGIiYlBdHQ0EhMTkZeXh4CAABQXF0s1QUFBSElJQVxcHOLi4pCSkoLg4GBpenFxMfr27Yvbt28jMTER0dHR2L59O6ZPn15zK0tERES1zkjfHaiqF198ES+++GKlNf/++y8mTZqEH374AX379tWaptFo8NVXX2Hjxo3o1asXAGDTpk1wdnbG/v374e/vj3PnziEuLg5HjhyBt7c3AGDt2rXw8fHBH3/8ATc3N+zbtw+///470tPTpaD1ySefYOTIkfjoo49gbW1dC2tPRERENa3ejAQ9TElJCYKDgzFjxgy0bdtWZ3pycjIKCwvh5+cntanVanh4eODw4cMAgKSkJCiVSikAAUCXLl2gVCq1ajw8PLRGmvz9/ZGfn4/k5OQK+5efn4/c3FytBxEREelPgwlBCxcuhJGREaZMmVLu9KysLJiYmMDGxkar3cnJCVlZWVKNo6OjzmsdHR21apycnLSm29jYwMTERKopT0REhHSekVKphLOzc7XWj4iIiGpWgwhBycnJWLFiBaKioqBQKKr1WiGE1mvKe/2j1JQ1Z84caDQa6ZGenl6tfhIREVHNahAh6Oeff0Z2djZcXFxgZGQEIyMjXLp0CdOnT4erqysAQKVSoaCgADk5OVqvzc7OlkZ2VCoVrly5ojP/q1evatWUHfHJyclBYWGhzgjRg0xNTWFtba31ICIiIv1pECEoODgYp0+fRkpKivRQq9WYMWMGfvjhBwCAl5cXjI2NER8fL70uMzMTZ86cga+vLwDAx8cHGo0Gx44dk2qOHj0KjUajVXPmzBlkZmZKNfv27YOpqSm8vLzqYnWJiIioBtSbq8Py8vJw8eJF6XlqaipSUlJga2sLFxcX2NnZadUbGxtDpVLBzc0NAKBUKjFmzBhMnz4ddnZ2sLW1RVhYGDw9PaWrxdq0aYM+ffogJCQEq1evBgCMGzcOAQEB0nz8/Pzg7u6O4OBgLF68GDdu3EBYWBhCQkI4ukNERFSP1JuRoBMnTqBjx47o2LEjAGDatGno2LEj3nvvvSrPY9myZejfvz8GDRqErl27wsLCArt374ahoaFUs3nzZnh6esLPzw9+fn5o164dNm7cKE03NDTE3r17YWZmhq5du2LQoEHo378/lixZUnMrS0RERLVOIYQQ+u6EHOXm5kKpVEKj0dTbESTFguqdhE41T8zj5ktUnzWEfUF9Vm9GgoiIiIhqEkMQERERyRJDEBEREckSQxARERHJEkMQERERyRJDEBEREckSQxARERHJEkMQERERyRJDEBEREckSQxARERHJEkMQERERyRJDEBEREckSQxARERHJEkMQERERyRJDEBEREckSQxARERHJEkMQERERyRJDEBEREckSQxARERHJEkMQERERyRJDEBEREckSQxARERHJEkMQERERyRJDEBEREckSQxARERHJEkMQERERyRJDEBEREckSQxARERHJEkMQERERyRJDEBEREckSQxARERHJEkMQERERyVK9CUE//fQT+vXrB7VaDYVCgZ07d0rTCgsLMWvWLHh6esLS0hJqtRrDhw9HRkaG1jzy8/MxefJk2Nvbw9LSEoGBgbh8+bJWTU5ODoKDg6FUKqFUKhEcHIybN29q1aSlpaFfv36wtLSEvb09pkyZgoKCgtpadSIiIqoF9SYE3b59G+3bt0dkZKTOtDt37uDkyZOYO3cuTp48iR07duDChQsIDAzUqgsNDUVMTAyio6ORmJiIvLw8BAQEoLi4WKoJCgpCSkoK4uLiEBcXh5SUFAQHB0vTi4uL0bdvX9y+fRuJiYmIjo7G9u3bMX369NpbeSIiIqpxCiGE0HcnqkuhUCAmJgb9+/evsOb48ePo3LkzLl26BBcXF2g0Gjg4OGDjxo0YPHgwACAjIwPOzs6IjY2Fv78/zp07B3d3dxw5cgTe3t4AgCNHjsDHxwfnz5+Hm5sbvv/+ewQEBCA9PR1qtRoAEB0djZEjRyI7OxvW1tZVWofc3FwolUpoNJoqv+a/RrFAoe8uyJ6YV+82XyJ6QEPYF9Rn9WYkqLo0Gg0UCgUaN24MAEhOTkZhYSH8/PykGrVaDQ8PDxw+fBgAkJSUBKVSKQUgAOjSpQuUSqVWjYeHhxSAAMDf3x/5+flITk6usD/5+fnIzc3VehAREZH+NMgQdO/ePcyePRtBQUFSss7KyoKJiQlsbGy0ap2cnJCVlSXVODo66szP0dFRq8bJyUlruo2NDUxMTKSa8kREREjnGSmVSjg7Oz/WOhIREdHjaXAhqLCwEEOGDEFJSQk+++yzh9YLIaBQ/N9hnQf//Tg1Zc2ZMwcajUZ6pKenP7RvREREVHsaVAgqLCzEoEGDkJqaivj4eK3jqyqVCgUFBcjJydF6TXZ2tjSyo1KpcOXKFZ35Xr16Vaum7IhPTk4OCgsLdUaIHmRqagpra2utBxEREelPgwlBpQHozz//xP79+2FnZ6c13cvLC8bGxoiPj5faMjMzcebMGfj6+gIAfHx8oNFocOzYManm6NGj0Gg0WjVnzpxBZmamVLNv3z6YmprCy8urNleRiIiIapCRvjtQVXl5ebh48aL0PDU1FSkpKbC1tYVarcbAgQNx8uRJ7NmzB8XFxdJoja2tLUxMTKBUKjFmzBhMnz4ddnZ2sLW1RVhYGDw9PdGrVy8AQJs2bdCnTx+EhIRg9erVAIBx48YhICAAbm5uAAA/Pz+4u7sjODgYixcvxo0bNxAWFoaQkBCO7hAREdUj9eYS+UOHDqFHjx467SNGjMD8+fPRrFmzcl938OBBdO/eHcD9E6ZnzJiBLVu24O7du+jZsyc+++wzrZOUb9y4gSlTpmDXrl0AgMDAQERGRkpXmQH3b5Y4ceJE/PjjjzA3N0dQUBCWLFkCU1PTKq9PQ7gskpfI6x8vkSeq3xrCvqA+qzchqKFpCF98hiD9Ywgiqt8awr6gPmsw5wQRERERVQdDEBEREckSQxARERHJEkMQERERyRJDEBEREckSQxARERHJEkMQERERyRJDEBEREckSQxARERHJEkMQERERyRJDEBEREckSQxARERHJEkMQERERyRJDEBEREckSQxARERHJEkMQERERyRJDEBEREckSQxARERHJEkMQERERyRJDEBEREckSQxARERHJEkMQERERyRJDEBEREckSQxARERHJEkMQERERyRJDEBEREckSQxARERHJEkMQERERyRJDEBEREckSQxARERHJEkMQERERyVK9CUE//fQT+vXrB7VaDYVCgZ07d2pNF0Jg/vz5UKvVMDc3R/fu3XH27Fmtmvz8fEyePBn29vawtLREYGAgLl++rFWTk5OD4OBgKJVKKJVKBAcH4+bNm1o1aWlp6NevHywtLWFvb48pU6agoKCgNlabiIiIakm9CUG3b99G+/btERkZWe70RYsWYenSpYiMjMTx48ehUqnQu3dv3Lp1S6oJDQ1FTEwMoqOjkZiYiLy8PAQEBKC4uFiqCQoKQkpKCuLi4hAXF4eUlBQEBwdL04uLi9G3b1/cvn0biYmJiI6Oxvbt2zF9+vTaW3kiIiKqcQohhNB3J6pLoVAgJiYG/fv3B3B/FEitViM0NBSzZs0CcH/Ux8nJCQsXLsT48eOh0Wjg4OCAjRs3YvDgwQCAjIwMODs7IzY2Fv7+/jh37hzc3d1x5MgReHt7AwCOHDkCHx8fnD9/Hm5ubvj+++8REBCA9PR0qNVqAEB0dDRGjhyJ7OxsWFtbV2kdcnNzoVQqodFoqvya/xrFAoW+uyB7Yl6923yJ6AENYV9Qn9WbkaDKpKamIisrC35+flKbqakpunXrhsOHDwMAkpOTUVhYqFWjVqvh4eEh1SQlJUGpVEoBCAC6dOkCpVKpVePh4SEFIADw9/dHfn4+kpOTa3U9iYiIqOYY6bsDNSErKwsA4OTkpNXu5OSES5cuSTUmJiawsbHRqSl9fVZWFhwdHXXm7+joqFVTdjk2NjYwMTGRasqTn5+P/Px86Xlubm5VV4+IiIhqQYMYCSqlUGgfnhFC6LSVVbamvPpHqSkrIiJCOtlaqVTC2dm50n4RERFR7WoQIUilUgGAzkhMdna2NGqjUqlQUFCAnJycSmuuXLmiM/+rV69q1ZRdTk5ODgoLC3VGiB40Z84caDQa6ZGenl7NtSQiIqKa1CBCULNmzaBSqRAfHy+1FRQUICEhAb6+vgAALy8vGBsba9VkZmbizJkzUo2Pjw80Gg2OHTsm1Rw9ehQajUar5syZM8jMzJRq9u3bB1NTU3h5eVXYR1NTU1hbW2s9iIiISH/qzTlBeXl5uHjxovQ8NTUVKSkpsLW1hYuLC0JDQxEeHo6WLVuiZcuWCA8Ph4WFBYKCggAASqUSY8aMwfTp02FnZwdbW1uEhYXB09MTvXr1AgC0adMGffr0QUhICFavXg0AGDduHAICAuDm5gYA8PPzg7u7O4KDg7F48WLcuHEDYWFhCAkJYbAhIiKqR+pNCDpx4gR69OghPZ82bRoAYMSIEYiKisLMmTNx9+5dTJw4ETk5OfD29sa+fftgZWUlvWbZsmUwMjLCoEGDcPfuXfTs2RNRUVEwNDSUajZv3owpU6ZIV5EFBgZq3ZvI0NAQe/fuxcSJE9G1a1eYm5sjKCgIS5Ysqe23gIiIiGpQvbxPUEPQEO4NwfsE6R/vE0RUvzWEfUF91iDOCSIiIiKqLoYgIiIikiWGICIiIpIlhiAiIiKSJYYgIiIikiWGICIiIpIlhiAiIiKSJYYgIiIikiWGICIiIpIlhiAiIiKSJYYgIiIikiWGICIiIpIlhiAiIiKSJYYgIiIikiWGICIiIpIlhiAiIiKSJYYgIiIikiWGICIiIpIlhiAiIiKSJYYgIiIikiWGICIiIpIlhiAiIiKSJYYgIiIikiWGICIiIpIlhiAiIiKSJYYgIiIikiWGICIiIpIlhiAiIiKSJYYgIiIikiWGICIiIpIlhiAiIiKSJYYgIiIikqUGFYKKiorw7rvvolmzZjA3N0fz5s3x/vvvo6SkRKoRQmD+/PlQq9UwNzdH9+7dcfbsWa355OfnY/LkybC3t4elpSUCAwNx+fJlrZqcnBwEBwdDqVRCqVQiODgYN2/erIvVJCIiohrQoELQwoUL8cUXXyAyMhLnzp3DokWLsHjxYqxatUqqWbRoEZYuXYrIyEgcP34cKpUKvXv3xq1bt6Sa0NBQxMTEIDo6GomJicjLy0NAQACKi4ulmqCgIKSkpCAuLg5xcXFISUlBcHBwna4vERERPTqFEELouxM1JSAgAE5OTvjqq6+ktgEDBsDCwgIbN26EEAJqtRqhoaGYNWsWgPujPk5OTli4cCHGjx8PjUYDBwcHbNy4EYMHDwYAZGRkwNnZGbGxsfD398e5c+fg7u6OI0eOwNvbGwBw5MgR+Pj44Pz583Bzc3toX3Nzc6FUKqHRaGBtbV0L70btUyxQ6LsLsifmNZjNl0iWGsK+oD5rUCNBzz77LA4cOIALFy4AAE6dOoXExES89NJLAIDU1FRkZWXBz89Peo2pqSm6deuGw4cPAwCSk5NRWFioVaNWq+Hh4SHVJCUlQalUSgEIALp06QKlUinVEBER0X+bkb47UJNmzZoFjUaD1q1bw9DQEMXFxfjoo48wdOhQAEBWVhYAwMnJSet1Tk5OuHTpklRjYmICGxsbnZrS12dlZcHR0VFn+Y6OjlJNWfn5+cjPz5ee5+bmPuJaEhERUU1oUCNB27Ztw6ZNm7BlyxacPHkS69evx5IlS7B+/XqtOoVC+zCOEEKnrayyNeXVVzafiIgI6SRqpVIJZ2fnqq4WERER1YIGFYJmzJiB2bNnY8iQIfD09ERwcDCmTp2KiIgIAIBKpQIAndGa7OxsaXRIpVKhoKAAOTk5ldZcuXJFZ/lXr17VGWUqNWfOHGg0GumRnp7+eCtLREREj6VBhaA7d+7AwEB7lQwNDaVL5Js1awaVSoX4+HhpekFBARISEuDr6wsA8PLygrGxsVZNZmYmzpw5I9X4+PhAo9Hg2LFjUs3Ro0eh0WikmrJMTU1hbW2t9SAiIiL9aVDnBPXr1w8fffQRXFxc0LZtW/z6669YunQpRo8eDeD+IazQ0FCEh4ejZcuWaNmyJcLDw2FhYYGgoCAAgFKpxJgxYzB9+nTY2dnB1tYWYWFh8PT0RK9evQAAbdq0QZ8+fRASEoLVq1cDAMaNG4eAgIAqXRlGRERE+tegQtCqVaswd+5cTJw4EdnZ2VCr1Rg/fjzee+89qWbmzJm4e/cuJk6ciJycHHh7e2Pfvn2wsrKSapYtWwYjIyMMGjQId+/eRc+ePREVFQVDQ0OpZvPmzZgyZYp0FVlgYCAiIyPrbmWJiIjosTSo+wTVJw3h3hC8T5D+8T5BRPVbQ9gX1GcN6pwgIiIioqpiCCIiIiJZYggiIiIiWWIIIiIiIlliCCIiIiJZYggiIiIiWWIIIiIiIlliCCIiIiJZYggiIiIiWWIIIiIiIlliCCIiIiJZYggiIiIiWWIIIiIiIlliCCIiIiJZYggiIiIiWWIIIiIiIlliCCIiIiJZYggiIiIiWWIIIiIiIlliCCIiIiJZYggiIiIiWWIIIiIiIlliCCIiIiJZYggiIiIiWWIIIiIiIlliCCIiIiJZYggiIiIiWWIIIiIiIlliCCIiIiJZYggiIiIiWWIIIiIiIlliCCIiIiJZanAh6N9//8Xrr78OOzs7WFhYoEOHDkhOTpamCyEwf/58qNVqmJubo3v37jh79qzWPPLz8zF58mTY29vD0tISgYGBuHz5slZNTk4OgoODoVQqoVQqERwcjJs3b9bFKhIREVENaFAhKCcnB127doWxsTG+//57/P777/jkk0/QuHFjqWbRokVYunQpIiMjcfz4cahUKvTu3Ru3bt2SakJDQxETE4Po6GgkJiYiLy8PAQEBKC4ulmqCgoKQkpKCuLg4xMXFISUlBcHBwXW5ukRERPQYFEIIoe9O1JTZs2fjl19+wc8//1zudCEE1Go1QkNDMWvWLAD3R32cnJywcOFCjB8/HhqNBg4ODti4cSMGDx4MAMjIyICzszNiY2Ph7++Pc+fOwd3dHUeOHIG3tzcA4MiRI/Dx8cH58+fh5ub20L7m5uZCqVRCo9HA2tq6ht6BuqVYoNB3F2RPzGswmy+RLDWEfUF91qBGgnbt2oVOnTrhtddeg6OjIzp27Ii1a9dK01NTU5GVlQU/Pz+pzdTUFN26dcPhw4cBAMnJySgsLNSqUavV8PDwkGqSkpKgVCqlAAQAXbp0gVKplGqIiIjov61BhaC///4bn3/+OVq2bIkffvgBEyZMwJQpU7BhwwYAQFZWFgDAyclJ63VOTk7StKysLJiYmMDGxqbSGkdHR53lOzo6SjVl5efnIzc3V+tBRERE+mOk7w7UpJKSEnTq1Anh4eEAgI4dO+Ls2bP4/PPPMXz4cKlOodA+jCOE0Gkrq2xNefWVzSciIgILFiyo8roQERFR7WpQI0FNmjSBu7u7VlubNm2QlpYGAFCpVACgM1qTnZ0tjQ6pVCoUFBQgJyen0porV67oLP/q1as6o0yl5syZA41GIz3S09MfYQ2JiIiopjSoENS1a1f88ccfWm0XLlxA06ZNAQDNmjWDSqVCfHy8NL2goAAJCQnw9fUFAHh5ecHY2FirJjMzE2fOnJFqfHx8oNFocOzYManm6NGj0Gg0Uk1ZpqamsLa21noQERGR/jSow2FTp06Fr68vwsPDMWjQIBw7dgxr1qzBmjVrANw/hBUaGorw8HC0bNkSLVu2RHh4OCwsLBAUFAQAUCqVGDNmDKZPnw47OzvY2toiLCwMnp6e6NWrF4D7o0t9+vRBSEgIVq9eDQAYN24cAgICqnRlGBEREelfgwpBzzzzDGJiYjBnzhy8//77aNasGZYvX45hw4ZJNTNnzsTdu3cxceJE5OTkwNvbG/v27YOVlZVUs2zZMhgZGWHQoEG4e/cuevbsiaioKBgaGko1mzdvxpQpU6SryAIDAxEZGVl3K0tERESPpUHdJ6g+aQj3huB9gvSP9wkiqt8awr6gPmtQ5wQRERERVRVDEBEREckSQxARERHJEkMQERERyRJDEBEREckSQxARERHJEkMQERERyRJDEBEREckSQxARERHJEkMQERERyRJDEBEREckSQxARERHJEkMQERERyRJDEBEREckSQxARERHJEkMQERERyRJDEBEREckSQxARERHJEkMQERERyZKRvjtARFSvKRT67gEJoe8eUD3FkSAiIiKSJYYgIiIikiWGICIiIpIlhiAiIiKSJYYgIiIikiWGICIiIpIlhiAiIiKSJYYgIiIikiWGICIiIpIlhiAiIiKSJYYgIiIikiWGICIiIpKlBhuCIiIioFAoEBoaKrUJITB//nyo1WqYm5uje/fuOHv2rNbr8vPzMXnyZNjb28PS0hKBgYG4fPmyVk1OTg6Cg4OhVCqhVCoRHByMmzdv1sFaERERUU1pkCHo+PHjWLNmDdq1a6fVvmjRIixduhSRkZE4fvw4VCoVevfujVu3bkk1oaGhiImJQXR0NBITE5GXl4eAgAAUFxdLNUFBQUhJSUFcXBzi4uKQkpKC4ODgOls/IiIienwNLgTl5eVh2LBhWLt2LWxsbKR2IQSWL1+Od955B6+++io8PDywfv163LlzB1u2bAEAaDQafPXVV/jkk0/Qq1cvdOzYEZs2bcJvv/2G/fv3AwDOnTuHuLg4fPnll/Dx8YGPjw/Wrl2LPXv24I8//tDLOhMREVH1NbgQ9Oabb6Jv377o1auXVntqaiqysrLg5+cntZmamqJbt244fPgwACA5ORmFhYVaNWq1Gh4eHlJNUlISlEolvL29pZouXbpAqVRKNeXJz89Hbm6u1oOIiIj0x0jfHahJ0dHROHnyJI4fP64zLSsrCwDg5OSk1e7k5IRLly5JNSYmJlojSKU1pa/PysqCo6OjzvwdHR2lmvJERERgwYIF1VshIiIiqjUNZiQoPT0db731FjZt2gQzM7MK6xQKhdZzIYROW1lla8qrf9h85syZA41GIz3S09MrXSYRERHVrgYTgpKTk5GdnQ0vLy8YGRnByMgICQkJWLlyJYyMjKQRoLKjNdnZ2dI0lUqFgoIC5OTkVFpz5coVneVfvXpVZ5TpQaamprC2ttZ6EBERkf40mBDUs2dP/Pbbb0hJSZEenTp1wrBhw5CSkoLmzZtDpVIhPj5eek1BQQESEhLg6+sLAPDy8oKxsbFWTWZmJs6cOSPV+Pj4QKPR4NixY1LN0aNHodFopBoiIiL672sw5wRZWVnBw8NDq83S0hJ2dnZSe2hoKMLDw9GyZUu0bNkS4eHhsLCwQFBQEABAqVRizJgxmD59Ouzs7GBra4uwsDB4enpKJ1q3adMGffr0QUhICFavXg0AGDduHAICAuDm5laHa0xERESPo8GEoKqYOXMm7t69i4kTJyInJwfe3t7Yt28frKyspJply5bByMgIgwYNwt27d9GzZ09ERUXB0NBQqtm8eTOmTJkiXUUWGBiIyMjIOl8fIiIienQKIYTQdyfkKDc3F0qlEhqNpt6eH6RYUPkJ5VT7xDxuvnr3kAsrqA7U491YQ9gX1GcN5pwgIiIioupgCCIiIiJZYggiIiIiWWIIIiIiIlliCCIiIiJZYggiIiIiWWIIIiIiIlliCCIiIiJZYggiIiIiWWIIIiIiIlliCCIiIiJZYggiIiIiWWIIIiIiIlliCCIiIiJZYggiIiIiWWIIIiIiIlliCCIiIiJZYggiIiIiWWIIIiIiIlliCCIiIiJZYggiIiIiWWIIIiIiIlliCCIiIiJZYggiIiIiWWIIIiIiIlliCCIiIiJZYggiIiIiWWIIIiIiIlliCCIiIiJZYggiIiIiWWIIIiIiIlliCCIiIiJZalAhKCIiAs888wysrKzg6OiI/v37448//tCqEUJg/vz5UKvVMDc3R/fu3XH27Fmtmvz8fEyePBn29vawtLREYGAgLl++rFWTk5OD4OBgKJVKKJVKBAcH4+bNm7W9ikRERFRDGlQISkhIwJtvvokjR44gPj4eRUVF8PPzw+3bt6WaRYsWYenSpYiMjMTx48ehUqnQu3dv3Lp1S6oJDQ1FTEwMoqOjkZiYiLy8PAQEBKC4uFiqCQoKQkpKCuLi4hAXF4eUlBQEBwfX6foSERHRo1MIIYS+O1Fbrl69CkdHRyQkJOD555+HEAJqtRqhoaGYNWsWgPujPk5OTli4cCHGjx8PjUYDBwcHbNy4EYMHDwYAZGRkwNnZGbGxsfD398e5c+fg7u6OI0eOwNvbGwBw5MgR+Pj44Pz583Bzc3to33Jzc6FUKqHRaGBtbV17b0ItUixQ6LsLsifmNdjNt/5QcDvQu3q8G2sI+4L6rEGNBJWl0WgAALa2tgCA1NRUZGVlwc/PT6oxNTVFt27dcPjwYQBAcnIyCgsLtWrUajU8PDykmqSkJCiVSikAAUCXLl2gVCqlmrLy8/ORm5ur9SAiIiL9abAhSAiBadOm4dlnn4WHhwcAICsrCwDg5OSkVevk5CRNy8rKgomJCWxsbCqtcXR01Fmmo6OjVFNWRESEdP6QUqmEs7Pz460gERERPZYGG4ImTZqE06dPY+vWrTrTFGWGr4UQOm1lla0pr76y+cyZMwcajUZ6pKenV2U1iIiIqJY0yBA0efJk7Nq1CwcPHsSTTz4ptatUKgDQGa3Jzs6WRodUKhUKCgqQk5NTac2VK1d0lnv16lWdUaZSpqamsLa21noQERGR/jSoECSEwKRJk7Bjxw78+OOPaNasmdb0Zs2aQaVSIT4+XmorKChAQkICfH19AQBeXl4wNjbWqsnMzMSZM2ekGh8fH2g0Ghw7dkyqOXr0KDQajVRDRERE/21G+u5ATXrzzTexZcsWfPfdd7CyspJGfJRKJczNzaFQKBAaGorw8HC0bNkSLVu2RHh4OCwsLBAUFCTVjhkzBtOnT4ednR1sbW0RFhYGT09P9OrVCwDQpk0b9OnTByEhIVi9ejUAYNy4cQgICKjSlWFERESkfw0qBH3++ecAgO7du2u1r1u3DiNHjgQAzJw5E3fv3sXEiRORk5MDb29v7Nu3D1ZWVlL9smXLYGRkhEGDBuHu3bvo2bMnoqKiYGhoKNVs3rwZU6ZMka4iCwwMRGRkZO2uIBEREdWYBn2foP+yhnBvCN4nSP94n6D/AN4nSP/q8W6sIewL6rMGdU4QERERUVUxBBEREZEsMQQRERGRLDEEERERkSwxBBEREZEsMQQRERGRLDEEERERkSwxBBEREZEsMQQRERGRLDEEERERkSwxBBEREZEsMQQRERGRLDEEERERkSwxBBEREZEsMQQRERGRLDEEERERkSwxBBEREZEsMQQRERGRLDEEERERkSwxBBEREZEsMQQRERGRLDEEERERkSwxBBEREZEsMQQRERGRLDEEERERkSwxBBEREZEsMQQRERGRLDEEERERkSwxBBEREZEsMQQRERGRLDEEERERkSwxBBEREZEsMQQ9hs8++wzNmjWDmZkZvLy88PPPP+u7S0RERFRFDEGPaNu2bQgNDcU777yDX3/9Fc899xxefPFFpKWl6btrREREVAUMQY9o6dKlGDNmDMaOHYs2bdpg+fLlcHZ2xueff67vrhEREVEVGOm7A/VRQUEBkpOTMXv2bK12Pz8/HD58uNzX5OfnIz8/X3qu0WgAALm5ubXX0dp2T98doHr9/SGqKfV4OyjdhoUQeu6JPDEEPYJr166huLgYTk5OWu1OTk7Iysoq9zURERFYsGCBTruzs3Ot9JHkQfmxUt9dINI/Zf3fDm7dugVlA1iP+oYh6DEoFAqt50IInbZSc+bMwbRp06TnJSUluHHjBuzs7Cp8DdWu3NxcODs7Iz09HdbW1vruDpFecDvQLyEEbt26BbVare+uyBJD0COwt7eHoaGhzqhPdna2zuhQKVNTU5iammq1NW7cuLa6SNVgbW3NH3+SPW4H+sMRIP3hidGPwMTEBF5eXoiPj9dqj4+Ph6+vr556RURERNXBkaBHNG3aNAQHB6NTp07w8fHBmjVrkJaWhgkTJui7a0RERFQFDEGPaPDgwbh+/Tref/99ZGZmwsPDA7GxsWjatKm+u0ZVZGpqinnz5ukcpiSSE24HJGcKwevyiIiISIZ4ThARERHJEkMQERERyRJDEBEREckSQxARERHJEkMQERERyRJDEBEREckSQxARERHJEkMQyc7GjRvRtWtXqNVqXLp0CQCwfPlyfPfdd3ruGVHd+fnnn/H666/Dx8cH//77L4D720ZiYqKee0ZUdxiCSFY+//xzTJs2DS+99BJu3ryJ4uJiAPf/M9vly5frt3NEdWT79u3w9/eHubk5fv31V+Tn5wMAbt26hfDwcD33jqjuMASRrKxatQpr167FO++8A0NDQ6m9U6dO+O233/TYM6K68+GHH+KLL77A2rVrYWxsLLX7+vri5MmTeuwZUd1iCCJZSU1NRceOHXXaTU1Ncfv2bT30iKju/fHHH3j++ed12q2trXHz5s267xCRnjAEkaw0a9YMKSkpOu3ff/893N3d675DRHrQpEkTXLx4Uac9MTERzZs310OPiPSD/4s8ycqMGTPw5ptv4t69exBC4NixY9i6dSsiIiLw5Zdf6rt7RHVi/PjxeOutt/D1119DoVAgIyMDSUlJCAsLw3vvvafv7hHVGf4v8iQ7a9euxYcffoj09HQAwBNPPIH58+djzJgxeu4ZUd155513sGzZMty7dw/A/UPCYWFh+OCDD/TcM6K6wxBEsnXt2jWUlJTA0dFR310h0os7d+7g999/R0lJCdzd3dGoUSN9d4moTvGcIJKVBQsW4K+//gIA2NvbMwCRLK1fvx63b9+GhYUFOnXqhM6dOzMAkSwxBJGsbN++Ha1atUKXLl0QGRmJq1ev6rtLRHUuLCwMjo6OGDJkCPbs2YOioiJ9d4lILxiCSFZOnz6N06dP44UXXsDSpUvxxBNP4KWXXsKWLVtw584dfXePqE5kZmZi27ZtMDQ0xJAhQ9CkSRNMnDgRhw8f1nfXiOoUzwkiWfvll1+wZcsW/O9//8O9e/eQm5ur7y4R1ak7d+4gJiYGW7Zswf79+/Hkk09Kh4yJGjpeIk+yZmlpCXNzc5iYmODWrVv67g5RnbOwsIC/vz9ycnJw6dIlnDt3Tt9dIqozPBxGspOamoqPPvoI7u7u6NSpE06ePIn58+cjKytL310jqjN37tzB5s2b8dJLL0GtVmPZsmXo378/zpw5o++uEdUZjgSRrPj4+ODYsWPw9PTEqFGjEBQUhCeeeELf3SKqU0OHDsXu3bthYWGB1157DYcOHYKvr6++u0VU5xiCSFZ69OiBL7/8Em3bttV3V4j0RqFQYNu2bfD394eREXcDJF88MZqIiIhkiX8CUIM3bdo0fPDBB7C0tMS0adMqrV26dGkd9Yqobq1cuRLjxo2DmZkZVq5cWWntlClT6qhXRPrFkSBq8Hr06IGYmBg0btwYPXr0qLT24MGDddQrorrVrFkznDhxAnZ2dmjWrFmFdQqFAn///Xcd9oxIfxiCiIiISJZ4iTzJyujRo8u9H9Dt27cxevRoPfSIqO69//775d4h/e7du3j//ff10CMi/eBIEMmKoaEhMjMzdf7j1GvXrkGlUvH/UCJZqGg7uH79OhwdHVFcXKynnhHVLZ4YTbKQm5sLIQSEELh16xbMzMykacXFxYiNjeX/KE+yIYSAQqHQaT916hRsbW310CMi/WAIIllo3LgxFAoFFAoFWrVqpTNdoVBgwYIFeugZUd2xsbHR2g4eDELFxcXIy8vDhAkT9NhDorrFw2EkCwkJCRBC4IUXXsD27du1/to1MTFB06ZNoVar9dhDotq3fv16CCEwevRoLF++HEqlUppmYmICV1dX+Pj46LGHRHWLIYhk5dKlS3BxcSn3UACRXCQkJMDX1xfGxsb67gqRXjEEUYN3+vRpeHh4wMDAAKdPn660tl27dnXUK6L/hrt376KwsFCrzdraWk+9IapbDEHU4BkYGCArKwuOjo4wMDCAQqFAeV97hULBq2JIFu7cuYOZM2fim2++wfXr13WmczsgueCJ0dTgpaamwsHBQfo3kdzNmDEDBw8exGeffYbhw4fj008/xb///ovVq1fj448/1nf3iOoMR4KIiGTGxcUFGzZsQPfu3WFtbY2TJ0/iqaeewsaNG7F161bExsbqu4tEdYJ3jCZZWb9+Pfbu3Ss9nzlzJho3bgxfX19cunRJjz0jqjs3btyQ/v8wa2tr3LhxAwDw7LPP4qefftJn14jqFEMQyUp4eDjMzc0BAElJSYiMjMSiRYtgb2+PqVOn6rl3RHWjefPm+OeffwAA7u7u+OabbwAAu3fvRuPGjfXXMaI6xsNhJCsWFhY4f/48XFxcMGvWLGRmZmLDhg04e/YsunfvjqtXr+q7i0S1btmyZTA0NMSUKVNw8OBB9O3bF8XFxSgqKsLSpUvx1ltv6buLRHWCJ0aTrDRq1AjXr1+Hi4sL9u3bJ43+mJmZ4e7du3ruHVHdeHDUs0ePHjh//jxOnDiBFi1aoH379nrsGVHdYggiWenduzfGjh2Ljh074sKFC+jbty8A4OzZs3B1ddVv54j0xMXFBS4uLvruBlGdYwgiWfn000/x7rvvIj09Hdu3b4ednR0AIDk5GUOHDtVz74jqxsqVK8ttVygUMDMzw1NPPYXnn38ehoaGddwzorrFc4KIiGSmWbNmuHr1Ku7cuQMbGxsIIXDz5k1YWFigUaNGyM7ORvPmzXHw4EE4Ozvru7tEtYZXh5Hs3Lx5E5988gnGjh2LkJAQLF26FBqNRt/dIqoz4eHheOaZZ/Dnn3/i+vXruHHjBi5cuABvb2+sWLECaWlpUKlUvGKSGjyOBJGsnDhxAv7+/jA3N0fnzp0hhMCJEydw9+5d7Nu3D08//bS+u0hU61q0aIHt27ejQ4cOWu2//vorBgwYgL///huHDx/GgAEDkJmZqZ9OEtUBnhNEsjJ16lQEBgZi7dq1MDK6//UvKirC2LFjERoayhvFkSxkZmaiqKhIp72oqAhZWVkAALVajVu3btV114jqFA+HkaycOHECs2bNkgIQABgZGWHmzJk4ceKEHntGVHd69OiB8ePH49dff5Xafv31V7zxxht44YUXAAC//fabdFdpooaKIYhkxdraGmlpaTrt6enpsLKy0kOPiOreV199BVtbW3h5ecHU1BSmpqbo1KkTbG1t8dVXXwG4f0+tTz75RM89JapdPCeIZGXKlCmIiYnBkiVL4OvrC4VCgcTERMyYMQMDBgzA8uXL9d1Fojpz/vx5XLhwAUIItG7dGm5ubvruElGd4jlBJCtLliyBgYEBhg8fLp0TYWxsjDfeeAMff/yxnntHVLeaN28OhUKBFi1aaB0iJpILjgSRLNy5cwczZszAzp07UVhYiB49emDSpElQKpV46qmnYGFhoe8uEtWZO3fuYPLkyVi/fj0A4MKFC2jevDmmTJkCtVqN2bNn67mHRHWD5wSRLMybNw9RUVHo27cvhg4dih9//BErV65Eu3btGIBIdubMmYNTp07h0KFDMDMzk9p79eqFbdu26bFnRHWL458kCzt27MBXX32FIUOGAACGDRuGrl27ori4mP81AMnOzp07sW3bNnTp0gUKhUJqd3d3x19//aXHnhHVLY4EkSykp6fjueeek5537twZRkZGyMjI0GOviPTj6tWrcHR01Gm/ffu2VigiaugYgkgWiouLYWJiotVmZGRU7g3jiBq6Z555Bnv37pWelwaftWvXwsfHR1/dIqpzPBxGsiCEwMiRI2Fqaiq13bt3DxMmTIClpaXUtmPHDn10j6hORUREoE+fPvj9999RVFSEFStW4OzZs0hKSkJCQoK+u0dUZ3h1GMnCqFGjqlS3bt26Wu4J0X/Db7/9hiVLliA5ORklJSV4+umnMWvWLHh6euq7a0R1hiGIiIiIZImHw4iIZMLAwOChJz4rFAqeK0eywRBERCQTMTExFU47fPgwVq1aBR4cIDnh4TAiIhk7f/485syZg927d2PYsGH44IMP4OLiou9uEdUJXiJPRCRDGRkZCAkJQbt27VBUVISUlBSsX7+eAYhkhSGIiEhGNBoNZs2ahaeeegpnz57FgQMHsHv3bnh4eOi7a0R1jucEERHJxKJFi7Bw4UKoVCps3boVL7/8sr67RKRXPCeIiEgmDAwMYG5ujl69elX6f+bxpqEkFxwJIiKSieHDh/P/BiN6AEeCiIiISJZ4YjQRERHJEkMQERERyRJDEBEREckSQxARAQAOHToEhUKBmzdv6rsrtWbkyJHo37//Y88nKioKjRs3fuz5EJF+MQQR/cdkZ2dj/PjxcHFxgampKVQqFfz9/ZGUlFRjy+jevTtCQ0O12nx9fZGZmQmlUlljy3lUFYUVhUIhPaysrNCpUye9XM49ePBgXLhwQXo+f/58dOjQoc77QUSPhyGI6D9mwIABOHXqFNavX48LFy5g165d6N69O27cuFGryzUxMYFKpfrPX0K9bt06ZGZm4vjx42jfvj1ee+21Gg2ID1NYWAhzc3M4OjrW2TKJqJYIIvrPyMnJEQDEoUOHKqy5efOmCAkJEQ4ODsLKykr06NFDpKSkSNPnzZsn2rdvLzZs2CCaNm0qrK2txeDBg0Vubq4QQogRI0YIAFqP1NRUcfDgQQFA5OTkCCGEWLdunVAqlWL37t2iVatWwtzcXAwYMEDk5eWJqKgo0bRpU9G4cWMxadIkUVRUJC0/Pz9fzJgxQ6jVamFhYSE6d+4sDh48KE0vnW9cXJxo3bq1sLS0FP7+/iIjI0Pqf9n+lb4egIiJiZHmVVBQICwsLMTs2bOFEEKcPn1a9OjRQ5iZmQlbW1sREhIibt26JdWPGDFCvPzyy9Lz77//XnTt2lUolUpha2sr+vbtKy5evChNT01NFQDEtm3bRLdu3YSpqan4+uuvpXUoXZ+y/V23bp0YNWqU6Nu3r9ZnV1hYKJycnMRXX31V4edLRHWHI0FE/yGNGjVCo0aNsHPnTuTn5+tMF0Kgb9++yMrKQmxsLJKTk/H000+jZ8+eWiNFf/31F3bu3Ik9e/Zgz549SEhIwMcffwwAWLFiBXx8fBASEoLMzExkZmbC2dm53P7cuXMHK1euRHR0NOLi4nDo0CG8+uqriI2NRWxsLDZu3Ig1a9bg22+/lV4zatQo/PLLL4iOjsbp06fx2muvoU+fPvjzzz+15rtkyRJs3LgRP/30E9LS0hAWFgYACAsLw6BBg9CnTx+pf76+vuX2z9jYGEZGRigsLMSdO3fQp08f2NjY4Pjx4/jf//6H/fv3Y9KkSRW+37dv38a0adNw/PhxHDhwAAYGBnjllVdQUlKiVTdr1ixMmTIF586dg7+/v9a0wYMHY/r06Wjbtq3U38GDB2Ps2LGIi4tDZmamVBsbG4u8vDwMGjSowj4RUR3SdwojIm3ffvutsLGxEWZmZsLX11fMmTNHnDp1SgghxIEDB4S1tbW4d++e1mtatGghVq9eLYS4P5JiYWEhjfwIIcSMGTOEt7e39Lxbt27irbfe0ppHeSNBALRGRsaPHy8sLCy0Rlf8/f3F+PHjhRBCXLx4USgUCvHvv/9qzbtnz55izpw5Fc73008/FU5OTtLzsiM2pfDASNC9e/fEBx98IACI2NhYsWbNGmFjYyPy8vKk+r179woDAwORlZVV6XxLZWdnCwDit99+E0L830jQ8uXLteoeHAkS4v9G38pyd3cXCxculJ73799fjBw5ssLlE1Hd4kgQ0X/MgAEDkJGRgV27dsHf3x+HDh3C008/jaioKCQnJyMvLw92dnbSqFGjRo2QmpqKv/76S5qHq6srrKyspOdNmjRBdnZ2tftiYWGBFi1aSM+dnJzg6uqKRo0aabWVzvvkyZMQQqBVq1Za/UtISNDqX9n5Vqd/Q4cORaNGjWBhYYGlS5diyZIlePHFF3Hu3Dm0b98elpaWUm3Xrl1RUlKCP/74o9x5/fXXXwgKCkLz5s1hbW2NZs2aAQDS0tK06jp16lSlvpU1duxYrFu3DsD9E9737t2L0aNHP9K8iKjm8f8OI/oPMjMzQ+/evdG7d2+89957GDt2LObNm4eJEyeiSZMmOHTokM5rHrxk29jYWGuaQqHQOcRTFeXNp7J5l5SUwNDQEMnJyTr/QeeDwam8eYgq/g8+y5YtQ69evWBtba11crIQosKTuitq79evH5ydnbF27Vqo1WqUlJTAw8MDBQUFWnUPBqvqGD58OGbPno2kpCQkJSXB1dUVzz333CPNi4hqHkMQUT3g7u6OnTt34umnn0ZWVhaMjIzg6ur6yPMzMTFBcXFxzXXw/+vYsSOKi4uRnZ39WDv7yvqnUqnw1FNP6bS7u7tj/fr1uH37thRafvnlFxgYGKBVq1Y69devX8e5c+ewevVqqa+JiYk12l87Ozv0798f69atQ1JSEkaNGvVI8yei2sHDYUT/IdevX8cLL7yATZs24fTp00hNTcX//vc/LFq0CC+//DJ69eoFHx8f9O/fHz/88AP++ecfHD58GO+++y5OnDhR5eW4urri6NGj+Oeff3Dt2rVHGiUqT6tWrTBs2DAMHz4cO3bsQGpqKo4fP46FCxciNja2Wv07ffo0/vjjD1y7dg2FhYUPfc2wYcNgZmaGESNG4MyZMzh48CAmT56M4OBgODk56dTb2NjAzs4Oa9aswcWLF/Hjjz9i2rRp1VrfB/ubmpqKlJQUXLt2Teuk9rFjx2L9+vU4d+4cRowY8UjzJ6LawRBE9B/SqFEjeHt7Y9myZXj++efh4eGBuXPnIiQkBJGRkVAoFIiNjcXzzz+P0aNHo1WrVhgyZAj++eefcnf0FQkLC4OhoSHc3d3h4OCgcw7M41i3bh2GDx+O6dOnw83NDYGBgTh69GiFV6CVJyQkBG5ubujUqRMcHBzwyy+/PPQ1FhYW+OGHH3Djxg0888wzGDhwIHr27InIyMhy6w0MDBAdHY3k5GR4eHhg6tSpWLx4cZX7+KABAwagT58+6NGjBxwcHLB161ZpWq9evdCkSRP4+/tDrVY/0vyJqHYoRFUPxBMRUbXduXMHarUaX3/9NV599VV9d4eIHsBzgoiIakFJSQmysrLwySefQKlUIjAwUN9dIqIyGIKIiGpBWloamjVrhieffBJRUVEwMuLPLdF/DQ+HERERkSzxxGgiIiKSJYYgIiIikiWGICIiIpIlhiAiIiKSJYYgIiIikiWGICIiIpIlhiAiIiKSJYYgIiIikiWGICIiIpKl/weCO5+6VeLuAwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Display distribution of Postive and Negative reviews in a bar graph\n",
    "sampled_dataset[\"SentimentPolarity\"].value_counts().plot(kind='bar',color=['green','red'],title='Distribution Of Positive and Negative reviews after De-Duplication.',figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11746995",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### In this code block :\n",
    "\n",
    "1. We define two functions which will remove the HTML tags and punctuations from each review.\n",
    "2. At the end of this code block, each review will contain texts which will only contain alphabetical strings. \n",
    "3. We will apply techniques such as stemming and stopwords removal.\n",
    "3. We will create two columns in the sampled dataset - 'CleanedText' and 'RemovedHTML'.\n",
    "4. 'CleanedText' column will basically contain the data corpus after stemming the each reviews and removing stopwords from each review. We will use this for our Bag of Word model.\n",
    "5. 'RemovedHTML' column will contain the data corpus from which only the HTML tags and punctuations are removed. We will use this column for our TF-IDF model, Average Word2Vec model and TF-IDF weighted average Word2Vec model.\n",
    "6. Store the final table in a dataset called 'sampled_dataset' for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55ce025c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "review = \"i am satisfied with the product , and the service is good... @  ! 7 % $ and the delivery is on time <br /> <br /> overall i am happy with the product.product\"\n",
    "\n",
    "\n",
    "'''Data Cleaning Stage. Clean each review from the sampled Amazon Dataset.'''\n",
    "#Data Cleaning Stage. Clean each review from the sampled Amazon Dataset\n",
    "\n",
    "#Function to clean html tags from a sentence\n",
    "def removeHtml(sentence): \n",
    "    pattern = re.compile('<.*?>')\n",
    "    cleaned_text = re.sub(pattern,' ',sentence)\n",
    "    return cleaned_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd706e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The review after removing html tags :  i am satisfied with the product , and the service is good... @  ! 7 % $ and the delivery is on time     overall i am happy with the product.product\n"
     ]
    }
   ],
   "source": [
    "cleaned_review=removeHtml(review)\n",
    "print(\"The review after removing html tags : \",cleaned_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af777f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to keep only words containing letters A-Z and a-z. This will remove all punctuations, special characters etc.\n",
    "def removePunctuations(sentence):\n",
    "    cleaned_text  = re.sub('[^a-zA-Z]',' ',sentence)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "71e09832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The review after removing  Punctuations :  i am satisfied with the product   and the service is good               and the delivery is on time     overall i am happy with the product product\n"
     ]
    }
   ],
   "source": [
    "cleaned_review_only_text = removePunctuations(cleaned_review)\n",
    "print(\"The review after removing  Punctuations : \",cleaned_review_only_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e67dad15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ineed to strip the text data and convert it into lower case\n",
    "#Function to convert the entire sentence to lower case and strip the extra spaces.  \n",
    "def stripLower(sentence):\n",
    "    cleaned_text = sentence.lower().strip()\n",
    "    cleaned_text = re.sub(' +', ' ', cleaned_text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d93c9136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The review after converting to lower case and stripping extra spaces :  i am satisfied with the product and the service is good and the delivery is on time overall i am happy with the product product\n"
     ]
    }
   ],
   "source": [
    "final_cleaned_review = stripLower(cleaned_review_only_text)\n",
    "print(\"The review after converting to lower case and stripping extra spaces : \",final_cleaned_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "270f39a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i am satisfied with the product and the service is good and the delivery is on time overall i am happy with the product product'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_cleaned_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19b313f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The review after taking only distinct words :  i am satisfied with the product and service is good delivery on time overall happy\n"
     ]
    }
   ],
   "source": [
    "def take_only_distinct_words(sentence):\n",
    "    word_tokens = sentence.split()\n",
    "    #print(\"The word tokens are : \", word_tokens)\n",
    "    seen = set()\n",
    "    cleaned_text = []\n",
    "    for word in word_tokens:\n",
    "        if word not in seen:\n",
    "            cleaned_text.append(word)\n",
    "            seen.add(word)\n",
    "    #print(\"The distinct words are : \", cleaned_text)\n",
    "    cleaned_text = ' '.join(cleaned_text)\n",
    "    return cleaned_text\n",
    "\n",
    "cleaned_review_distinct_words = take_only_distinct_words(final_cleaned_review)\n",
    "print(\"The review after taking only distinct words : \", cleaned_review_distinct_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3ad0fd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\life\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk   #spacy\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e9a1ed7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " \"he's\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " \"i've\",\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " \"we've\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c79a9fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\life\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# my next step is to remove stop words from the text data\n",
    "#Function to remove stop words from a sentence  \n",
    "nltk.download('stopwords')\n",
    "def removeStopWords(sentence):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    # need to take all negative words from the stop words in list after that we will remove those words from the stop words\n",
    "    #print(\"The stop words are : \", stop_words)\n",
    "    negative_words = [\"not\", \"no\", \"nor\", \"never\", \"don't\", \"didn't\", \"doesn't\", \"isn't\", \"wasn't\", \"shouldn't\", \"wouldn't\", \"couldn't\", \"won't\", \"haven't\", \"hasn't\", \"hadn't\", \"mightn't\", \"mustn't\", \"shan't\"]\n",
    "    #print(\"The negative words are : \", negative_words)\n",
    "    stop_words = stop_words - set(negative_words)\n",
    "    word_tokens = sentence.split()\n",
    "    cleaned_text = [word for word in word_tokens if not word in stop_words]\n",
    "    cleaned_text = ' '.join(cleaned_text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "113698fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_after_stopwords = removeStopWords(cleaned_review_distinct_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a17bffe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#example_review_for_stemming = \"i am satisfied with the product and the service is good and satisfy overall the satisfaction is good\"\n",
    "rev_test = \"satisfy  satisfied  satisfied satisfaction satisfactory satisfyingly\"\n",
    "# next step is to use stemming or  lemmatisation on the text data:\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "def stemming(sentence):\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    word_tokens = sentence.split()\n",
    "    cleaned_text = [porter_stemmer.stem(word) for word in word_tokens]\n",
    "    cleaned_text = ' '.join(cleaned_text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f2fca0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The review after stemming :  satisfi satisfi satisfi satisfact satisfactori satisfyingli\n"
     ]
    }
   ],
   "source": [
    "review_after_stemming = stemming(rev_test)\n",
    "print(\"The review after stemming : \",review_after_stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3b39caaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to use the stemming technique with snowball stemmer\n",
    "def stemming_with_snowball(sentence):\n",
    "    from nltk.stem.snowball import SnowballStemmer\n",
    "    snowball_stemmer = SnowballStemmer(language='english')\n",
    "    word_tokens = sentence.split()\n",
    "    cleaned_text = [snowball_stemmer.stem(word) for word in word_tokens]\n",
    "    cleaned_text = ' '.join(cleaned_text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "23d62706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The review after snowball stemmer :  satisfi satisfi satisfi satisfact satisfactori satisfi\n"
     ]
    }
   ],
   "source": [
    "review_after_snowball_stemming = stemming_with_snowball(rev_test)\n",
    "print(\"The review after snowball stemmer : \",review_after_snowball_stemming)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d178ffff",
   "metadata": {},
   "source": [
    "Stemming Vs Lemmatisation Explanation:\n",
    "Stemming and lemmatization are both techniques used in natural language processing (NLP) to reduce words to their base or root form, but they do so in different ways and with different levels of accuracy.\n",
    "Stemming:\n",
    "Stemming is a crude heuristic process that chops off the ends of words in the hope of achieving the correct base form of the word. It often involves removing common prefixes or suffixes. Stemming algorithms, such as the Porter Stemmer or Snowball Stemmer, use simple rules to perform this task.\n",
    "Lemmatisation:\n",
    "Lemmatisation, on the other hand, is a more sophisticated process that considers the context and the morphological analysis of words. It involves using a vocabulary and morphological analysis of words to return the base or dictionary form of a word, known as the lemma. Lemmatisation takes into account the part of speech and the meaning of the word, which often results in more accurate base forms. For example, the lemma of \"better\" is \"good,\" and the lemma of \"running\" is \"run.\"\n",
    "Lemmatisation typically requires more computational resources and is slower than stemming due to its complexity and reliance on linguistic knowledge.\n",
    "\n",
    "\n",
    "Stemming is faster and more efficient, while lemmatization is more accurate and context-aware. The choice between the two depends on the specific requirements of the NLP task at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e53a38a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The review after lemmatization :  satisfy satisfied satisfied satisfaction satisfactory satisfyingly\n"
     ]
    }
   ],
   "source": [
    "def lemmatization(sentence):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    word_tokens = sentence.split()\n",
    "    cleaned_text = [lemmatizer.lemmatize(word) for word in word_tokens]\n",
    "    cleaned_text = ' '.join(cleaned_text)\n",
    "    return cleaned_text\n",
    "\n",
    "review_after_lemmatization = lemmatization(rev_test)\n",
    "print(\"The review after lemmatization : \",review_after_lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "09bbbe18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Text</th>\n",
       "      <th>SentimentPolarity</th>\n",
       "      <th>Class_Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1351209600</td>\n",
       "      <td>This stuff is great for my non-black tea drink...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1351209600</td>\n",
       "      <td>I have used Alessi Decaffenated Caffe'Expresso...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Time                                               Text  \\\n",
       "0  1351209600  This stuff is great for my non-black tea drink...   \n",
       "1  1351209600  I have used Alessi Decaffenated Caffe'Expresso...   \n",
       "\n",
       "  SentimentPolarity  Class_Labels  \n",
       "0          Positive             1  \n",
       "1          Positive             1  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "de4e30d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(sentence):\n",
    "    sentence = removeHtml(sentence)\n",
    "    sentence = removePunctuations(sentence)\n",
    "    sentence = stripLower(sentence)\n",
    "    sentence = take_only_distinct_words(sentence)\n",
    "    sentence = removeStopWords(sentence)\n",
    "    sentence = stemming(sentence)\n",
    "    return sentence\n",
    "# we will call this function for each and every review in our dataset\n",
    "sampled_dataset['Cleaned_Text'] = sampled_dataset['Text'].apply(data_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "86d2c470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Text</th>\n",
       "      <th>SentimentPolarity</th>\n",
       "      <th>Class_Labels</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1351209600</td>\n",
       "      <td>This stuff is great for my non-black tea drink...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>stuff great non black tea drink friend nice ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1351209600</td>\n",
       "      <td>I have used Alessi Decaffenated Caffe'Expresso...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>use alessi decaffen caff expresso year sometim...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Time                                               Text  \\\n",
       "0  1351209600  This stuff is great for my non-black tea drink...   \n",
       "1  1351209600  I have used Alessi Decaffenated Caffe'Expresso...   \n",
       "\n",
       "  SentimentPolarity  Class_Labels  \\\n",
       "0          Positive             1   \n",
       "1          Positive             1   \n",
       "\n",
       "                                        Cleaned_Text  \n",
       "0  stuff great non black tea drink friend nice ba...  \n",
       "1  use alessi decaffen caff expresso year sometim...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fdd47943",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_dataset = sampled_dataset[['Time','Cleaned_Text','Class_Labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e8e86591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21892, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "      <th>Class_Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1351209600</td>\n",
       "      <td>stuff great non black tea drink friend nice ba...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1351209600</td>\n",
       "      <td>use alessi decaffen caff expresso year sometim...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1351209600</td>\n",
       "      <td>purchas item review highli anoth web site disa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1351209600</td>\n",
       "      <td>bought eden brand find tast better recommend g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1351209600</td>\n",
       "      <td>go lot garlic oliv oil use mani savori dish hu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Time                                       Cleaned_Text  Class_Labels\n",
       "0  1351209600  stuff great non black tea drink friend nice ba...             1\n",
       "1  1351209600  use alessi decaffen caff expresso year sometim...             1\n",
       "2  1351209600  purchas item review highli anoth web site disa...             1\n",
       "3  1351209600  bought eden brand find tast better recommend g...             1\n",
       "4  1351209600  go lot garlic oliv oil use mani savori dish hu...             1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sampled_dataset.shape)\n",
    "sampled_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ccd95d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class_Labels\n",
       "1    17099\n",
       "0     4793\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_dataset['Class_Labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9d026598",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data set into train and test sets. The test set should be unseen. Time Based Splitting Step 2.\n",
    "#The top old 80% data will get into the train set. The latest 20% data will get into the test set.\n",
    "def splitting_data(data):\n",
    "    X = data['Cleaned_Text']\n",
    "    y = data['Class_Labels']\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c2b00260",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = splitting_data(sampled_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "538101af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        stuff great non black tea drink friend nice ba...\n",
       "1        use alessi decaffen caff expresso year sometim...\n",
       "2        purchas item review highli anoth web site disa...\n",
       "3        bought eden brand find tast better recommend g...\n",
       "4        go lot garlic oliv oil use mani savori dish hu...\n",
       "                               ...                        \n",
       "21887    usual purchas item smaller link pound stash fr...\n",
       "21888    beauti repackag camper van beethoven first thr...\n",
       "21889    beetlejuic stori ghost alec baldwin geena davi...\n",
       "21890    michael keaton alreadi way major star play gho...\n",
       "21891    happen say name three time michael keaten star...\n",
       "Name: Cleaned_Text, Length: 21892, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e14022d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "21887    1\n",
       "21888    1\n",
       "21889    1\n",
       "21890    1\n",
       "21891    1\n",
       "Name: Class_Labels, Length: 21892, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "54822997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The split value is :  17513\n"
     ]
    }
   ],
   "source": [
    "# taking first 80% data as train data and last 20% data as test data\n",
    "split = math.floor(0.8*len(X))\n",
    "print(\"The split value is : \", split)\n",
    "X_train = X[0:split,] ; y_train = y[0:split,]\n",
    "\n",
    "X_test = X[split:,] ; y_test = y[split:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1d9b3b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17513,)\n",
      "(4379,)\n",
      "(17513,)\n",
      "(4379,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "02e6f67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        stuff great non black tea drink friend nice ba...\n",
       "1        use alessi decaffen caff expresso year sometim...\n",
       "2        purchas item review highli anoth web site disa...\n",
       "3        bought eden brand find tast better recommend g...\n",
       "4        go lot garlic oliv oil use mani savori dish hu...\n",
       "                               ...                        \n",
       "17508    well super mix high qualiti dog food ye cost j...\n",
       "17509    product great howev local supermarket carri co...\n",
       "17510    okay box x box equal serv total ounc buy produ...\n",
       "17511    plan use everyth even picki roommat never eat ...\n",
       "17512    year old eat soup sinc absolut love organ heal...\n",
       "Name: Cleaned_Text, Length: 17513, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bace8161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17513    normal mix rub pretti happi result came across...\n",
       "17514    not usual one flavor coffe save wonder hazelnu...\n",
       "17515    need pickl pork hock decid heck order sampler ...\n",
       "17516    vitamuffin absolut yummi first bought alreadi ...\n",
       "17517    warn even make food licens anoth compani look ...\n",
       "                               ...                        \n",
       "21887    usual purchas item smaller link pound stash fr...\n",
       "21888    beauti repackag camper van beethoven first thr...\n",
       "21889    beetlejuic stori ghost alec baldwin geena davi...\n",
       "21890    michael keaton alreadi way major star play gho...\n",
       "21891    happen say name three time michael keaten star...\n",
       "Name: Cleaned_Text, Length: 4379, dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8ee92b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "17508    1\n",
       "17509    1\n",
       "17510    0\n",
       "17511    1\n",
       "17512    1\n",
       "Name: Class_Labels, Length: 17513, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "64f6823e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17513    1\n",
       "17514    1\n",
       "17515    1\n",
       "17516    1\n",
       "17517    0\n",
       "        ..\n",
       "21887    1\n",
       "21888    1\n",
       "21889    1\n",
       "21890    1\n",
       "21891    1\n",
       "Name: Class_Labels, Length: 4379, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858510b2",
   "metadata": {},
   "source": [
    "Normalisation vs Standaridation\n",
    "Label Encoder vs One Hot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4cc5ad47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to calculate the total uniwue words in the text data of X_train data\n",
    "def total_unique_words(corpus):\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "    unique_words = vectorizer.get_feature_names_out()\n",
    "    return unique_words, len(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "60379e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words: 17399\n",
      "Sample unique words: ['aa' 'aaaaaahhhhh' 'aaahhh' 'aacur' 'aafco' 'aah' 'aakaufman' 'aar' 'ab'\n",
      " 'aback' 'abalon' 'abandon' 'abash' 'abbazabba' 'abbey' 'abbott' 'abc'\n",
      " 'abd' 'abdi' 'abdomin']\n"
     ]
    }
   ],
   "source": [
    "# Calculate total unique words in X_train\n",
    "unique_words, num_unique_words = total_unique_words(X_train)\n",
    "print(\"Total unique words:\", num_unique_words)\n",
    "print(\"Sample unique words:\", unique_words[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0616c4c2",
   "metadata": {},
   "source": [
    "# we need to convert text data into numerical data\n",
    "# we will use bag of words or tfidf vectorizer to convert text data into numerical data\n",
    "# bag of words VS TF-IDF\n",
    "# we will use tfidf vectorizer to convert text data into numerical data\n",
    "\n",
    "BOW and TF-IDF Explanation:\n",
    "Bag of Words (BoW) \n",
    "and Term Frequency-Inverse Document Frequency (TF-IDF)\n",
    "\n",
    "With example by taking few sentences as below:\n",
    "sentence1 = \"I love programming in Python\"\n",
    "sentence2 = \"Python is a great programming language\"\n",
    "sentence3 = \"I enjoy solving problems with Python\"\n",
    "\n",
    "BOW Formulation:\n",
    "1. Create a vocabulary of unique words from all sentences.\n",
    "vocabulary = [\"I\", \"love\", \"programming\", \"in\", \"Python\", \"is\", \"a\", \"great\", \"language\", \"enjoy\", \"solving\", \"problems\", \"with\"]\n",
    "len(vocabulary) = 13\n",
    "2. Represent each sentence as a vector based on the frequency of words in the vocabulary.\n",
    "maintain the count of each word in one dictionary to see the count of each and every words\n",
    "words_count = {\n",
    "    \"I\": 2,\n",
    "    \"love\": 1,\n",
    "    \"programming\": 2,\n",
    "    \"in\": 1,\n",
    "     \"Python\": 3,\n",
    "    \"is\": 1,\n",
    "    \"a\": 1,\n",
    "    \"great\": 1,\n",
    "    \"language\": 1,\n",
    "    \"enjoy\": 1,\n",
    "    \"solving\": 1,\n",
    "    \"problems\": 1,\n",
    "    \"with\": 1\n",
    "}\n",
    "# Example BOW vectors\n",
    "sentence1 = \"I love programming in Python\"\n",
    "sentence1_vector = [2, 1, 2, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "TF-IDF Formulation:\n",
    "1. Calculate Term Frequency (TF) for each word in a sentence.  \n",
    "TF(word) = (Number of times word appears in a sentence) / (Total number of words in the sentence)\n",
    "TF(\"Python\", sentence1) = 1/5 = 0.2\n",
    "TF(\"programming\", sentence1) = 1/5 = 0.2\n",
    "TF(\"I\", sentence1) = 1/5 = 0.2\n",
    "TF(\"love\", sentence1) = 1/5 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "06d3e307",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function to convert text data into numerical data using Bag of words and need to save that count vetorizer object in pickle file for test data conversion\n",
    "def text_to_bow(corpus):\n",
    "    cv_object = CountVectorizer()\n",
    "    X_bow = cv_object.fit_transform(corpus)\n",
    "    # we need to save this cv_object in pickle file for test data conversion\n",
    "    # saving the count vectorizer object in pickle file\n",
    "    with open('count_vectorizer.pkl', 'wb') as f:\n",
    "        pickle.dump(cv_object, f)\n",
    "    return X_bow, cv_object\n",
    "\n",
    "\n",
    "X_bow , cv_object = text_to_bow(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "91049a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bow_array = X_bow.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "658b05e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17513, 17399)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "911eb368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        stuff great non black tea drink friend nice ba...\n",
       "1        use alessi decaffen caff expresso year sometim...\n",
       "2        purchas item review highli anoth web site disa...\n",
       "3        bought eden brand find tast better recommend g...\n",
       "4        go lot garlic oliv oil use mani savori dish hu...\n",
       "                               ...                        \n",
       "17508    well super mix high qualiti dog food ye cost j...\n",
       "17509    product great howev local supermarket carri co...\n",
       "17510    okay box x box equal serv total ounc buy produ...\n",
       "17511    plan use everyth even picki roommat never eat ...\n",
       "17512    year old eat soup sinc absolut love organ heal...\n",
       "Name: Cleaned_Text, Length: 17513, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a16c6be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a4e3aad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MultinomialNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model using the training sets\n",
    "model.fit(X_bow,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b15daccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the response for test dataset\n",
    "y_train_pred = model.predict(X_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "516ae126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8967624050705191\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d40147ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[ 2745  1271]\n",
      " [  537 12960]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_train, y_train_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "# we need to convert the X_test data into numerical data using the count vectorizer object which"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "48d87645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report on train data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.68      0.75      4016\n",
      "           1       0.91      0.96      0.93     13497\n",
      "\n",
      "    accuracy                           0.90     17513\n",
      "   macro avg       0.87      0.82      0.84     17513\n",
      "weighted avg       0.89      0.90      0.89     17513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report on train data:\\n\", classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5267b6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to convert the text data into numerical data by using saved count vectorizer object\n",
    "# loading the count vectorizer object from pickle file\n",
    "#Create a function to convert text data into numerical data using Bag of words for test data conversion\n",
    "def text_to_bow_test(corpus):\n",
    "    with open('count_vectorizer.pkl', 'rb') as f:\n",
    "        loaded_cv_object = pickle.load(f)\n",
    "    X_bow = loaded_cv_object.transform(corpus)\n",
    "    return X_bow\n",
    "\n",
    "X_test_bow = text_to_bow_test(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "754213a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c292a6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report on test data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.47      0.56       777\n",
      "           1       0.89      0.96      0.92      3602\n",
      "\n",
      "    accuracy                           0.87      4379\n",
      "   macro avg       0.79      0.71      0.74      4379\n",
      "weighted avg       0.86      0.87      0.86      4379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classiffication report\n",
    "print(\"Classification Report on test data:\\n\", classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a2e5e35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>DecisionTreeClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we need to try with decision tree classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4232be2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report on train data using Decision Tree Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4016\n",
      "           1       1.00      1.00      1.00     13497\n",
      "\n",
      "    accuracy                           1.00     17513\n",
      "   macro avg       1.00      1.00      1.00     17513\n",
      "weighted avg       1.00      1.00      1.00     17513\n",
      "\n",
      "Classification Report on test data using Decision Tree Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.44      0.43       777\n",
      "           1       0.88      0.86      0.87      3602\n",
      "\n",
      "    accuracy                           0.79      4379\n",
      "   macro avg       0.65      0.65      0.65      4379\n",
      "weighted avg       0.80      0.79      0.79      4379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_dt = dt_model.predict(X_bow)\n",
    "y_test_pred_dt = dt_model.predict(X_test_bow)\n",
    "print(\"Classification Report on train data using Decision Tree Classifier:\\n\", classification_report(y_train,y_train_pred_dt))\n",
    "print(\"Classification Report on test data using Decision Tree Classifier:\\n\", classification_report(y_test,y_test_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8d6f2af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report on train data using Random Forest Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4016\n",
      "           1       1.00      1.00      1.00     13497\n",
      "\n",
      "    accuracy                           1.00     17513\n",
      "   macro avg       1.00      1.00      1.00     17513\n",
      "weighted avg       1.00      1.00      1.00     17513\n",
      "\n",
      "Classification Report on test data using Random Forest Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.22      0.35       777\n",
      "           1       0.86      0.99      0.92      3602\n",
      "\n",
      "    accuracy                           0.86      4379\n",
      "   macro avg       0.87      0.61      0.64      4379\n",
      "weighted avg       0.86      0.86      0.82      4379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# now we will try on Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_bow, y_train)\n",
    "y_train_pred_rf = rf_model.predict(X_bow)\n",
    "y_test_pred_rf = rf_model.predict(X_test_bow)   \n",
    "print(\"Classification Report on train data using Random Forest Classifier:\\n\", classification_report(y_train,y_train_pred_rf))\n",
    "print(\"Classification Report on test data using Random Forest Classifier:\\n\", classification_report(y_test,y_test_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5f2cef45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report on train data using XGBoost Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.71      0.81      4016\n",
      "           1       0.92      0.99      0.95     13497\n",
      "\n",
      "    accuracy                           0.92     17513\n",
      "   macro avg       0.93      0.85      0.88     17513\n",
      "weighted avg       0.92      0.92      0.92     17513\n",
      "\n",
      "Classification Report on test data using XGBoost Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.45      0.55       777\n",
      "           1       0.89      0.96      0.92      3602\n",
      "\n",
      "    accuracy                           0.87      4379\n",
      "   macro avg       0.80      0.70      0.73      4379\n",
      "weighted avg       0.86      0.87      0.86      4379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# now we will try with Xgboost classifier\n",
    "import xgboost as xgb\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_model.fit(X_bow, y_train)\n",
    "y_train_pred_xgb = xgb_model.predict(X_bow)\n",
    "y_test_pred_xgb = xgb_model.predict(X_test_bow)\n",
    "print(\"Classification Report on train data using XGBoost Classifier:\\n\", classification_report(y_train,y_train_pred_xgb))\n",
    "print(\"Classification Report on test data using XGBoost Classifier:\\n\", classification_report(y_test,y_test_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f16d4f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-3.0.5-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\life\\anaconda3\\lib\\site-packages (from xgboost) (2.1.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\life\\anaconda3\\lib\\site-packages (from xgboost) (1.15.3)\n",
      "Downloading xgboost-3.0.5-py3-none-win_amd64.whl (56.8 MB)\n",
      "   ---------------------------------------- 0.0/56.8 MB ? eta -:--:--\n",
      "   - -------------------------------------- 2.6/56.8 MB 22.0 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 4.7/56.8 MB 12.1 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 6.0/56.8 MB 9.7 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 6.8/56.8 MB 8.2 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 8.1/56.8 MB 7.6 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 9.2/56.8 MB 7.2 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 9.4/56.8 MB 6.9 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 10.0/56.8 MB 5.6 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 10.2/56.8 MB 5.1 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 10.5/56.8 MB 4.8 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 10.7/56.8 MB 4.6 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 11.3/56.8 MB 4.3 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 11.8/56.8 MB 4.1 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 12.1/56.8 MB 4.0 MB/s eta 0:00:12\n",
      "   --------- ------------------------------ 12.8/56.8 MB 3.9 MB/s eta 0:00:12\n",
      "   --------- ------------------------------ 13.1/56.8 MB 3.8 MB/s eta 0:00:12\n",
      "   --------- ------------------------------ 13.9/56.8 MB 3.7 MB/s eta 0:00:12\n",
      "   ---------- ----------------------------- 14.7/56.8 MB 3.7 MB/s eta 0:00:12\n",
      "   ---------- ----------------------------- 15.5/56.8 MB 3.7 MB/s eta 0:00:12\n",
      "   ----------- ---------------------------- 16.5/56.8 MB 3.7 MB/s eta 0:00:11\n",
      "   ------------ --------------------------- 17.6/56.8 MB 3.8 MB/s eta 0:00:11\n",
      "   ------------ --------------------------- 18.4/56.8 MB 3.8 MB/s eta 0:00:11\n",
      "   ------------- -------------------------- 19.7/56.8 MB 3.9 MB/s eta 0:00:10\n",
      "   -------------- ------------------------- 20.7/56.8 MB 3.9 MB/s eta 0:00:10\n",
      "   --------------- ------------------------ 21.5/56.8 MB 4.0 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 22.8/56.8 MB 4.0 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 24.1/56.8 MB 4.1 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 25.7/56.8 MB 4.2 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 27.0/56.8 MB 4.2 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 28.0/56.8 MB 4.2 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 28.8/56.8 MB 4.2 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 29.6/56.8 MB 4.2 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 30.7/56.8 MB 4.2 MB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 31.7/56.8 MB 4.2 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 32.8/56.8 MB 4.2 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 33.6/56.8 MB 4.3 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 34.1/56.8 MB 4.2 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 34.9/56.8 MB 4.2 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 35.4/56.8 MB 4.1 MB/s eta 0:00:06\n",
      "   ------------------------- -------------- 36.2/56.8 MB 4.1 MB/s eta 0:00:06\n",
      "   -------------------------- ------------- 37.0/56.8 MB 4.1 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 37.7/56.8 MB 4.1 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 38.8/56.8 MB 4.1 MB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 39.8/56.8 MB 4.1 MB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 40.9/56.8 MB 4.1 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 42.2/56.8 MB 4.1 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 43.5/56.8 MB 4.2 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 44.6/56.8 MB 4.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 46.1/56.8 MB 4.2 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 47.4/56.8 MB 4.3 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 48.8/56.8 MB 4.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 50.1/56.8 MB 4.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 51.4/56.8 MB 4.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 52.4/56.8 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 53.2/56.8 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 53.7/56.8 MB 4.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 54.5/56.8 MB 4.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 55.3/56.8 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  56.1/56.8 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  56.6/56.8 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  56.6/56.8 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  56.6/56.8 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 56.8/56.8 MB 4.1 MB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-3.0.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ddd1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Classifier -- is the combination of multiple decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "194c8e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 384 candidates, totalling 768 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ntrain data -- 30,000 rows\\ncv = 3\\n30,000/3 = 10,000 rows in each fold\\n2fold for training and 1 fold for validation\\n\\nfor example if we take CV=5\\n30,000/5 = 6,000 rows in each fold\\n4 folds for training and 1 fold for validation\\n\\nTrain data, Validation data, test data\\n'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to do Hyperparameter tuning for all the models to improve the accuracy and other metrics\n",
    "# We need to do cross validation for all the models to improve the accuracy and other metrics\n",
    "# first we will do hyperparameter tuning for Random Forest Classifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [None, 10],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'bootstrap': [True, False],\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "#comb1 -- 50, None, 2, 1, auto, True,None, gini\n",
    "#comb2 -- 50, None, 2, 1, auto, True,None, entropy\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=2, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_bow, y_train)\n",
    "\n",
    "'''\n",
    "train data -- 30,000 rows\n",
    "cv = 3\n",
    "30,000/3 = 10,000 rows in each fold\n",
    "2fold for training and 1 fold for validation\n",
    "    \n",
    "for example if we take CV=5\n",
    "30,000/5 = 6,000 rows in each fold\n",
    "4 folds for training and 1 fold for validation\n",
    "\n",
    "Train data, Validation data, test data\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "616b61f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'class_weight': 'balanced',\n",
       " 'criterion': 'entropy',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ae31b093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report on train data using Tuned Random Forest Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.05      0.09      4016\n",
      "           1       0.78      1.00      0.88     13497\n",
      "\n",
      "    accuracy                           0.78     17513\n",
      "   macro avg       0.89      0.52      0.48     17513\n",
      "weighted avg       0.83      0.78      0.70     17513\n",
      "\n",
      "Classification Report on test data using Tuned Random Forest Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.01       777\n",
      "           1       0.82      1.00      0.90      3602\n",
      "\n",
      "    accuracy                           0.82      4379\n",
      "   macro avg       0.91      0.50      0.45      4379\n",
      "weighted avg       0.85      0.82      0.74      4379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_model_tuned = RandomForestClassifier(n_estimators=200, max_depth=20, min_samples_split=5, min_samples_leaf=1, max_features='sqrt', bootstrap=True, class_weight=None, criterion='gini')\n",
    "rf_model_tuned.fit(X_bow, y_train)\n",
    "y_train_pred_rf_tuned = rf_model_tuned.predict(X_bow)\n",
    "y_test_pred_rf_tuned = rf_model_tuned.predict(X_test_bow)\n",
    "print(\"Classification Report on train data using Tuned Random Forest Classifier:\\n\", classification_report(y_train,y_train_pred_rf_tuned))\n",
    "print(\"Classification Report on test data using Tuned Random Forest Classifier:\\n\", classification_report(y_test,y_test_pred_rf_tuned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "807f4dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With above code still if we are not getting accuracy let us apply Over sampling on the training dataset\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5fa919b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26994, 17399)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "535f8b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "26989    0\n",
       "26990    0\n",
       "26991    0\n",
       "26992    0\n",
       "26993    0\n",
       "Name: Class_Labels, Length: 26994, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fab2170b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report on train data using Tuned Random Forest Classifier after OverSampling:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83      4016\n",
      "           1       0.96      0.94      0.95     13497\n",
      "\n",
      "    accuracy                           0.92     17513\n",
      "   macro avg       0.88      0.90      0.89     17513\n",
      "weighted avg       0.92      0.92      0.92     17513\n",
      "\n",
      "Classification Report on test data using Tuned Random Forest Classifier after OverSampling:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.64      0.61       777\n",
      "           1       0.92      0.90      0.91      3602\n",
      "\n",
      "    accuracy                           0.85      4379\n",
      "   macro avg       0.75      0.77      0.76      4379\n",
      "weighted avg       0.86      0.85      0.86      4379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# build the random forest model on the resampled data\n",
    "rf_model_tuned = RandomForestClassifier(n_estimators=200, max_depth=20, min_samples_split=5, min_samples_leaf=1, max_features='sqrt', bootstrap=True, class_weight=None, criterion='gini')\n",
    "rf_model_tuned.fit(X_resampled, y_resampled)\n",
    "y_train_pred_rf_tuned = rf_model_tuned.predict(X_bow)\n",
    "y_test_pred_rf_tuned = rf_model_tuned.predict(X_test_bow)\n",
    "print(\"Classification Report on train data using Tuned Random Forest Classifier after OverSampling:\\n\", classification_report(y_train,y_train_pred_rf_tuned))\n",
    "print(\"Classification Report on test data using Tuned Random Forest Classifier after OverSampling:\\n\", classification_report(y_test,y_test_pred_rf_tuned))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daffa865",
   "metadata": {},
   "source": [
    "### next steps to try tfidf and build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d44f98e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert train data into tfidf vectorizer\n",
    "def text_to_tfidf(corpus):\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    X_tfidf = tfidf_vectorizer.fit_transform(corpus)\n",
    "    # we need to save this tfidf_vectorizer object in pickle file for test data conversion\n",
    "    # saving the tfidf vectorizer object in pickle file\n",
    "    with open('tfidf_vectorizer.pkl', 'wb') as f:\n",
    "        pickle.dump(tfidf_vectorizer, f)\n",
    "    return X_tfidf, tfidf_vectorizer\n",
    "\n",
    "X_tfidf , tfidf_vectorizer = text_to_tfidf(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff445cce",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73f21b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##To add XGBClassifier with hyperparameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3bce64f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 256 candidates, totalling 512 fits\n",
      "Best XGBClassifier Params: {'colsample_bytree': 0.8, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100, 'reg_alpha': 0, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "Classification Report on train data using Tuned XGBClassifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.51      0.65      4016\n",
      "           1       0.87      0.98      0.92     13497\n",
      "\n",
      "    accuracy                           0.87     17513\n",
      "   macro avg       0.89      0.75      0.79     17513\n",
      "weighted avg       0.88      0.87      0.86     17513\n",
      "\n",
      "Classification Report on test data using Tuned XGBClassifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.35      0.47       777\n",
      "           1       0.87      0.97      0.92      3602\n",
      "\n",
      "    accuracy                           0.86      4379\n",
      "   macro avg       0.80      0.66      0.70      4379\n",
      "weighted avg       0.85      0.86      0.84      4379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning for XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [3, 6],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "    'gamma': [0, 1],\n",
    "    'reg_alpha': [0, 0.5],\n",
    "    'reg_lambda': [1, 2]\n",
    "}\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_grid_search = GridSearchCV(estimator=xgb_model, param_grid=xgb_param_grid, cv=2, n_jobs=-1, verbose=2)\n",
    "xgb_grid_search.fit(X_bow, y_train)\n",
    "\n",
    "print(\"Best XGBClassifier Params:\", xgb_grid_search.best_params_)\n",
    "\n",
    "# Train XGBClassifier with best params\n",
    "xgb_best = xgb.XGBClassifier(**xgb_grid_search.best_params_, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_best.fit(X_bow, y_train)\n",
    "y_train_pred_xgb_best = xgb_best.predict(X_bow)\n",
    "y_test_pred_xgb_best = xgb_best.predict(X_test_bow)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report on train data using Tuned XGBClassifier:\\n\", classification_report(y_train, y_train_pred_xgb_best))\n",
    "print(\"Classification Report on test data using Tuned XGBClassifier:\\n\", classification_report(y_test, y_test_pred_xgb_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc766bc",
   "metadata": {},
   "source": [
    "##Use RandomForestClassifier to check the accuracy \n",
    "##To add RandomForestClassifier with hyperparameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "73667ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report on train data using Random Forest Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4016\n",
      "           1       1.00      1.00      1.00     13497\n",
      "\n",
      "    accuracy                           1.00     17513\n",
      "   macro avg       1.00      1.00      1.00     17513\n",
      "weighted avg       1.00      1.00      1.00     17513\n",
      "\n",
      "Classification Report on test data using Random Forest Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.23      0.37       777\n",
      "           1       0.86      0.99      0.92      3602\n",
      "\n",
      "    accuracy                           0.86      4379\n",
      "   macro avg       0.86      0.61      0.64      4379\n",
      "weighted avg       0.86      0.86      0.82      4379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Train RandomForestClassifier\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_bow, y_train)\n",
    "\n",
    "# Predict on train and test data\n",
    "y_train_pred_rf = rf_model.predict(X_bow)\n",
    "y_test_pred_rf = rf_model.predict(X_test_bow)\n",
    "\n",
    "# Print classification reports\n",
    "print(\"Classification Report on train data using Random Forest Classifier:\\n\", classification_report(y_train, y_train_pred_rf))\n",
    "print(\"Classification Report on test data using Random Forest Classifier:\\n\", classification_report(y_test, y_test_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27553636",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest classifier is giving the best results so we will save this model for future use\n",
    "# saving the random forest model in pickle file for future use\n",
    "    pickle.dump(rf_model, f)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
